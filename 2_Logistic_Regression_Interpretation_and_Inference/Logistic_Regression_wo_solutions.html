<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Louis OLIVE">

<title>Logistic regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="Logistic_Regression_wo_solutions_files/libs/clipboard/clipboard.min.js"></script>
<script src="Logistic_Regression_wo_solutions_files/libs/quarto-html/quarto.js"></script>
<script src="Logistic_Regression_wo_solutions_files/libs/quarto-html/popper.min.js"></script>
<script src="Logistic_Regression_wo_solutions_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Logistic_Regression_wo_solutions_files/libs/quarto-html/anchor.min.js"></script>
<link href="Logistic_Regression_wo_solutions_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Logistic_Regression_wo_solutions_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Logistic_Regression_wo_solutions_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Logistic_Regression_wo_solutions_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Logistic_Regression_wo_solutions_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script>
  MathJax = {
    tex: {
      tags: 'ams'  // should be 'ams', 'none', or 'all'
    }
  };
</script>

<link href="Logistic_Regression_wo_solutions_files/libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet">
<script src="Logistic_Regression_wo_solutions_files/libs/pagedtable-1.1/js/pagedtable.js"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#the-logistic-regression-model" id="toc-the-logistic-regression-model" class="nav-link active" data-scroll-target="#the-logistic-regression-model"><span class="header-section-number">1</span> The Logistic Regression model</a>
  <ul class="collapse">
  <li><a href="#informal-introductory-example" id="toc-informal-introductory-example" class="nav-link" data-scroll-target="#informal-introductory-example"><span class="header-section-number">1.1</span> Informal introductory example</a></li>
  <li><a href="#a-more-formal-definition" id="toc-a-more-formal-definition" class="nav-link" data-scroll-target="#a-more-formal-definition"><span class="header-section-number">1.2</span> A more formal definition</a></li>
  <li><a href="#estimation" id="toc-estimation" class="nav-link" data-scroll-target="#estimation"><span class="header-section-number">1.3</span> Estimation</a>
  <ul class="collapse">
  <li><a href="#maximum-likelihood-estimation" id="toc-maximum-likelihood-estimation" class="nav-link" data-scroll-target="#maximum-likelihood-estimation"><span class="header-section-number">1.3.1</span> Maximum Likelihood Estimation</a></li>
  <li><a href="#numerical-methods" id="toc-numerical-methods" class="nav-link" data-scroll-target="#numerical-methods"><span class="header-section-number">1.3.2</span> Numerical methods</a></li>
  <li><a href="#logistic-regression-as-a-machine-learning-approach" id="toc-logistic-regression-as-a-machine-learning-approach" class="nav-link" data-scroll-target="#logistic-regression-as-a-machine-learning-approach"><span class="header-section-number">1.3.3</span> Logistic Regression as a machine learning approach</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#interpretation" id="toc-interpretation" class="nav-link" data-scroll-target="#interpretation"><span class="header-section-number">2</span> Interpretation</a>
  <ul class="collapse">
  <li><a href="#coefficients" id="toc-coefficients" class="nav-link" data-scroll-target="#coefficients"><span class="header-section-number">2.1</span> Coefficients</a></li>
  <li><a href="#odds" id="toc-odds" class="nav-link" data-scroll-target="#odds"><span class="header-section-number">2.2</span> Odds</a></li>
  <li><a href="#odds-ratio" id="toc-odds-ratio" class="nav-link" data-scroll-target="#odds-ratio"><span class="header-section-number">2.3</span> Odds ratio</a></li>
  </ul></li>
  <li><a href="#inference" id="toc-inference" class="nav-link" data-scroll-target="#inference"><span class="header-section-number">3</span> Inference</a>
  <ul class="collapse">
  <li><a href="#asymptotic-properties-of-mle" id="toc-asymptotic-properties-of-mle" class="nav-link" data-scroll-target="#asymptotic-properties-of-mle"><span class="header-section-number">3.1</span> Asymptotic properties of MLE</a></li>
  <li><a href="#wald-statistics" id="toc-wald-statistics" class="nav-link" data-scroll-target="#wald-statistics"><span class="header-section-number">3.2</span> Wald statistics</a>
  <ul class="collapse">
  <li><a href="#confidence-intervals" id="toc-confidence-intervals" class="nav-link" data-scroll-target="#confidence-intervals"><span class="header-section-number">3.2.1</span> Confidence intervals</a></li>
  <li><a href="#tests-on-model-coefficients" id="toc-tests-on-model-coefficients" class="nav-link" data-scroll-target="#tests-on-model-coefficients"><span class="header-section-number">3.2.2</span> Tests on model coefficients</a></li>
  </ul></li>
  <li><a href="#likelihood-ratio-tests" id="toc-likelihood-ratio-tests" class="nav-link" data-scroll-target="#likelihood-ratio-tests"><span class="header-section-number">3.3</span> Likelihood ratio tests</a></li>
  <li><a href="#goodness-of-fit-test-calibration" id="toc-goodness-of-fit-test-calibration" class="nav-link" data-scroll-target="#goodness-of-fit-test-calibration"><span class="header-section-number">3.4</span> Goodness of Fit test / Calibration</a></li>
  </ul></li>
  <li><a href="#variable-selection-model-assessment" id="toc-variable-selection-model-assessment" class="nav-link" data-scroll-target="#variable-selection-model-assessment"><span class="header-section-number">4</span> Variable selection, model assessment</a>
  <ul class="collapse">
  <li><a href="#best-subset" id="toc-best-subset" class="nav-link" data-scroll-target="#best-subset"><span class="header-section-number">4.1</span> Best subset</a></li>
  <li><a href="#stepwise-logistic-regression" id="toc-stepwise-logistic-regression" class="nav-link" data-scroll-target="#stepwise-logistic-regression"><span class="header-section-number">4.2</span> Stepwise Logistic Regression</a></li>
  <li><a href="#introducing-penalized-logistic-regressions" id="toc-introducing-penalized-logistic-regressions" class="nav-link" data-scroll-target="#introducing-penalized-logistic-regressions"><span class="header-section-number">4.3</span> Introducing penalized logistic regressions</a></li>
  <li><a href="#model-assessment" id="toc-model-assessment" class="nav-link" data-scroll-target="#model-assessment"><span class="header-section-number">4.4</span> Model assessment</a>
  <ul class="collapse">
  <li><a href="#hold-out-approach" id="toc-hold-out-approach" class="nav-link" data-scroll-target="#hold-out-approach"><span class="header-section-number">4.4.1</span> Hold-out approach</a></li>
  <li><a href="#k-fold-cross-validation-approach" id="toc-k-fold-cross-validation-approach" class="nav-link" data-scroll-target="#k-fold-cross-validation-approach"><span class="header-section-number">4.4.2</span> K-fold Cross-Validation approach</a></li>
  </ul></li>
  <li><a href="#exercise---case-study" id="toc-exercise---case-study" class="nav-link" data-scroll-target="#exercise---case-study"><span class="header-section-number">4.5</span> Exercise - case study</a>
  <ul class="collapse">
  <li><a href="#eda" id="toc-eda" class="nav-link" data-scroll-target="#eda"><span class="header-section-number">4.5.1</span> EDA</a></li>
  <li><a href="#coefficient-interpretation" id="toc-coefficient-interpretation" class="nav-link" data-scroll-target="#coefficient-interpretation"><span class="header-section-number">4.5.2</span> Coefficient interpretation</a></li>
  <li><a href="#tests" id="toc-tests" class="nav-link" data-scroll-target="#tests"><span class="header-section-number">4.5.3</span> Tests</a></li>
  <li><a href="#stepwise-logistic-regression-1" id="toc-stepwise-logistic-regression-1" class="nav-link" data-scroll-target="#stepwise-logistic-regression-1"><span class="header-section-number">4.5.4</span> Stepwise Logistic Regression</a></li>
  <li><a href="#penalized-logistic-regression" id="toc-penalized-logistic-regression" class="nav-link" data-scroll-target="#penalized-logistic-regression"><span class="header-section-number">4.5.5</span> Penalized Logistic Regression</a></li>
  <li><a href="#model-assessment-1" id="toc-model-assessment-1" class="nav-link" data-scroll-target="#model-assessment-1"><span class="header-section-number">4.5.6</span> Model assessment</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">5</span> References</a></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Logistic regression</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Louis OLIVE </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="the-logistic-regression-model" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> The Logistic Regression model</h1>
<section id="informal-introductory-example" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="informal-introductory-example"><span class="header-section-number">1.1</span> Informal introductory example</h2>
<p>We provide here some intuitions leading to the Logistic Regression model using a simulated data set from <span class="citation" data-cites="islr2021">James et al. (<a href="#ref-islr2021" role="doc-biblioref">2021</a>)</span> (the <strong>Default</strong> data set).</p>
<p>This is a toy data set used for teaching purposes containing information on ten thousand customers.</p>
<p>The aim here is to assess which customers will <strong><em>default</em></strong> on their credit card debt (the target or response variable) based on the current credit card <strong><em>balance</em></strong> and other individual characteristics (the predictors or feature vector).</p>
<p>This is a binary classification problem as the <strong><em>default</em></strong> variable takes value in a discrete set (here binary). In the following we will denote <span class="math inline">\(Y\)</span> the output or response variable and <span class="math inline">\(X = (X_0,X_1,\cdots,X_{p-1})^{T}\)</span> the feature vector or inputs.</p>
<p>The approach we follow is similar to <span class="citation" data-cites="hosmer2013">(<a href="#ref-hosmer2013" role="doc-biblioref">Hosmer, Lemeshow, and Sturdivant 2013</a>)</span> or <span class="citation" data-cites="cornillon2019">(<a href="#ref-cornillon2019" role="doc-biblioref">Cornillon and Matzner-Løber 2019</a>)</span>. Both books use a similar example: the presence or absence of a Coronary Heart Disease (CHD) is explained with the age of an individual (the data set <em>chdage</em> is available in companion package <em>aplore3</em>).</p>
<p>We can start to explore the Default data with a scatterplot (<a href="#fig-default_balance-scatterplot">Figure&nbsp;1</a>) of the target variable (<strong><em>default</em></strong>) with respect to a predictor (<strong><em>balance</em></strong>):</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Default data set (simulated) from ESLII/ISLR</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>default_data <span class="ot">&lt;-</span> ISLR2<span class="sc">::</span>Default <span class="sc">%&gt;%</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as_tibble</span>()</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(default_data, <span class="fu">aes</span>(<span class="at">x=</span>balance, <span class="at">y=</span>default)) <span class="sc">+</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">geom_point</span>(<span class="at">alpha=</span><span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-default_balance-scatterplot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Logistic_Regression_wo_solutions_files/figure-html/fig-default_balance-scatterplot-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Scatterplot of variable <strong><em>default</em></strong> with respect to credit card <strong><em>balance</em></strong> for 10000 customers</figcaption>
</figure>
</div>
</div>
</div>
<p>In this scatterplot, all points fall on one of two parallel lines representing the absence (No) or occurrence (Yes) of <strong><em>default</em></strong>. We “jitter” the data vertically to avoid overplotting. The plot below shows that the response variable is imbalanced towards the absence of default:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(default_data, <span class="fu">aes</span>(<span class="at">x=</span>balance, <span class="at">y=</span>default)) <span class="sc">+</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">geom_jitter</span>(<span class="at">alpha=</span><span class="fl">0.2</span>, <span class="at">height=</span><span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="Logistic_Regression_wo_solutions_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>We also show the boxplots of credit cards <strong><em>balance</em></strong> with respect to <strong><em>default</em></strong> status:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(default_data,</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(<span class="at">x=</span>default, <span class="at">y=</span>balance)) <span class="sc">+</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">geom_boxplot</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-balance_default-boxplot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Logistic_Regression_wo_solutions_files/figure-html/fig-balance_default-boxplot-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Variable <strong><em>balance</em></strong> with respect to <strong><em>default</em></strong> status</figcaption>
</figure>
</div>
</div>
</div>
<p>We can see from <a href="#fig-default_balance-scatterplot">Figure&nbsp;1</a> and <a href="#fig-balance_default-boxplot">Figure&nbsp;2</a> that default tends to be more prevalent for accounts with a high balance. However it is difficult to guess a simple relationship between default and balance.</p>
<p>To investigate further we discretise the balance variables by classes of width <span class="math inline">\(300\$\)</span> and compute the mean of response variable (<strong><em>default</em></strong> is Yes) within each balance class:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>class_width <span class="ot">&lt;-</span> <span class="dv">300</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>(default_data_binned <span class="ot">&lt;-</span> default_data <span class="sc">%&gt;%</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">balance_bins =</span> <span class="fu">cut</span>(balance, <span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">3000</span>, class_width),</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>                              <span class="at">right =</span> <span class="cn">FALSE</span>, <span class="at">dig.lab =</span> <span class="dv">4</span>),</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>           <span class="at">min =</span> <span class="fu">floor</span>(balance <span class="sc">/</span> class_width) <span class="sc">*</span> class_width,</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>           <span class="at">max =</span> <span class="fu">if_else</span>(balance <span class="sc">==</span> <span class="dv">0</span> , <span class="dv">1</span>, </span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>                         <span class="co"># customers with 0$ balance should be long to [0, width) class</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>                         <span class="co"># or be excluded</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>                         <span class="fu">ceiling</span>(balance <span class="sc">/</span> class_width))  <span class="sc">*</span> class_width) <span class="sc">%&gt;%</span> </span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(balance_bins, min, max, default) <span class="sc">%&gt;%</span> </span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(<span class="at">n=</span><span class="fu">n</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> default, <span class="at">values_from =</span> n) <span class="sc">%&gt;%</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">replace_na</span>(<span class="fu">list</span>(<span class="at">Yes =</span> <span class="dv">0</span>, <span class="at">No =</span> <span class="dv">0</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="st">`</span><span class="at">Mean(default)</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">round</span>(Yes <span class="sc">/</span> (Yes <span class="sc">+</span> No), <span class="dv">4</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">

<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":["balance_bins"],"name":[1],"type":["fct"],"align":["left"]},{"label":["min"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["max"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["No"],"name":[4],"type":["int"],"align":["right"]},{"label":["Yes"],"name":[5],"type":["int"],"align":["right"]},{"label":["Mean(default)"],"name":[6],"type":["dbl"],"align":["right"]}],"data":[{"1":"[0,300)","2":"0","3":"300","4":"1497","5":"0","6":"0.0000"},{"1":"[300,600)","2":"300","3":"600","4":"1784","5":"0","6":"0.0000"},{"1":"[600,900)","2":"600","3":"900","4":"2305","5":"3","6":"0.0013"},{"1":"[900,1200)","2":"900","3":"1200","4":"2098","5":"19","6":"0.0090"},{"1":"[1200,1500)","2":"1200","3":"1500","4":"1330","5":"53","6":"0.0383"},{"1":"[1500,1800)","2":"1500","3":"1800","4":"527","5":"96","6":"0.1541"},{"1":"[1800,2100)","2":"1800","3":"2100","4":"115","5":"114","6":"0.4978"},{"1":"[2100,2400)","2":"2100","3":"2400","4":"11","5":"41","6":"0.7885"},{"1":"[2400,2700)","2":"2400","3":"2700","4":"0","5":"7","6":"1.0000"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<p>In the following we map, by convention and for better readability, the response variable <span class="math inline">\(Y \in\{Yes, No\}\)</span> to <span class="math inline">\(\{0, 1\}\)</span>:</p>
<p><span class="math display">\[
Y = \left\{ \begin{array}{ll}
    1&amp;  \mbox{if customer defaulted on its credit card (ie default=Yes)}\cr
    0&amp;  \mbox{otherwise}.
    \end{array} \right.
\]</span></p>
<p>Then we plot the mean of default (in red) within each balance class (of width <span class="math inline">\(300\$\)</span>):</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>(default_occurrence <span class="ot">&lt;-</span> </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">ggplot</span>(default_data <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">default =</span> <span class="fu">if_else</span>(default <span class="sc">==</span> <span class="st">"Yes"</span>, <span class="dv">1</span>, <span class="dv">0</span>)), <span class="fu">aes</span>(<span class="at">x=</span>balance, <span class="at">y=</span>default)) <span class="sc">+</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a> <span class="fu">geom_point</span>(<span class="at">alpha=</span><span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a> <span class="fu">geom_segment</span>(<span class="at">data =</span> default_data_binned,</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">x =</span> min, <span class="at">xend =</span> max, <span class="at">y =</span> <span class="st">`</span><span class="at">Mean(default)</span><span class="st">`</span>, <span class="at">yend =</span> <span class="st">`</span><span class="at">Mean(default)</span><span class="st">`</span>),</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">color =</span> <span class="st">'coral'</span>,</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">linewidth=</span><span class="fl">1.25</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-balance_default-scatterplot-occurrence" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Logistic_Regression_wo_solutions_files/figure-html/fig-balance_default-scatterplot-occurrence-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Mean occurrence of <strong><em>default</em></strong> within <strong><em>balance</em></strong> classes</figcaption>
</figure>
</div>
</div>
</div>
<p>The relationship between the mean occurrence of <strong><em>default</em></strong> and <strong><em>balance</em></strong> is easier to read.</p>
<p><a href="#fig-balance_default-scatterplot-occurrence">Figure&nbsp;3</a> clearly shows that as balance increases, the proportion of customers defaulting on their credit card increases.</p>
<p>We also notice that the mean default occurrence with respect to balance classes follows a kind of “S”-shaped curve or <strong>sigmoid</strong> function. Note that the shape depends on classes width and might change.</p>
<p>Going further and informally, considering that the mean of default occurrence is an estimate of <span class="math inline">\(\mathbf{E}[Y|X=x]\)</span> for each balance classes an idea would be to model:</p>
<p><span class="math display">\[
\mathbb{E}[Y|X=x] = \mu_\beta(x)
\]</span></p>
<p>where <span class="math inline">\(\mu_\beta\)</span> is a <strong>sigmoid</strong> function in <span class="math inline">\([0,1]\)</span>.</p>
<p>The Logistic Regression model uses the <strong>sigmoid</strong> function <span class="math inline">\(\sigma: x \to\sigma(x)=\frac{e^{x}} { 1 + e^{x} }\)</span> also known as logistic function.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>(default_occurrence <span class="sc">+</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"glm"</span>, </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">formula =</span> y <span class="sc">~</span> x,</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">method.args =</span> <span class="fu">list</span>(<span class="at">family =</span> <span class="st">"binomial"</span>), </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>             <span class="at">se =</span> <span class="cn">FALSE</span>,</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>             <span class="at">col =</span> <span class="st">"dodgerblue"</span>,</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>             <span class="at">linetype =</span> <span class="st">"dotted"</span>) <span class="sc">+</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a> <span class="fu">geom_segment</span>(<span class="at">data =</span> default_data_binned,</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">x =</span> min, <span class="at">xend =</span> max, <span class="at">y =</span> <span class="st">`</span><span class="at">Mean(default)</span><span class="st">`</span>, <span class="at">yend =</span> <span class="st">`</span><span class="at">Mean(default)</span><span class="st">`</span>),</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>              <span class="at">color =</span> <span class="st">'coral'</span>,</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>              <span class="at">linewidth=</span><span class="fl">1.25</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="Logistic_Regression_wo_solutions_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Another approach would have been to treat <span class="math inline">\(Y\)</span> as a quantitative response variable and fit a simple linear model:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>linear <span class="ot">&lt;-</span> <span class="fu">lm</span>(default <span class="sc">~</span> balance, <span class="at">data =</span> default_data <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">default =</span> <span class="fu">if_else</span>(default <span class="sc">==</span> <span class="st">"Yes"</span>, <span class="dv">1</span>, <span class="dv">0</span>)))</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co">#summary(linear)</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>coeff_lm <span class="ot">&lt;-</span> linear<span class="sc">$</span>coefficients</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> coeff_lm[<span class="st">"(Intercept)"</span>]</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">&lt;-</span> coeff_lm[<span class="st">"balance"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>(<span class="fu">ggplot</span>(default_data <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">default =</span> <span class="fu">if_else</span>(default <span class="sc">==</span> <span class="st">"Yes"</span>, <span class="dv">1</span>, <span class="dv">0</span>)), <span class="fu">aes</span>(<span class="at">x=</span>balance, <span class="at">y=</span>default)) <span class="sc">+</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">geom_point</span>(<span class="at">alpha=</span><span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a> <span class="fu">geom_segment</span>(<span class="at">data =</span> default_data_binned,</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">x =</span> min, <span class="at">xend =</span> max, <span class="at">y =</span> <span class="st">`</span><span class="at">Mean(default)</span><span class="st">`</span>, <span class="at">yend =</span> <span class="st">`</span><span class="at">Mean(default)</span><span class="st">`</span>),</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>              <span class="at">color =</span> <span class="st">'coral'</span>,</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">size=</span><span class="fl">1.25</span>)<span class="sc">+</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a> <span class="fu">geom_line</span>(<span class="at">data =</span> <span class="fu">tibble</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">3000</span>, <span class="dv">300</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>               <span class="fu">mutate</span>(<span class="at">y =</span> alpha <span class="sc">+</span> beta <span class="sc">*</span> x),</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>           <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y),</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>           <span class="at">color =</span> <span class="st">'darkolivegreen'</span>,</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>           <span class="at">linetype =</span> <span class="st">'dotted'</span>))</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a> <span class="co"># Alternatively we could have used the geom_smooth command</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a> <span class="co"># geom_smooth(method = "lm", </span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a> <span class="co">#             formula = y ~ x,</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a> <span class="co">#             se = FALSE,</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a> <span class="co">#             col = "darkolivegreen",</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a> <span class="co">#             linetype = "dotted")</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-balance_default-scatterplot-lmfit" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Logistic_Regression_wo_solutions_files/figure-html/fig-balance_default-scatterplot-lmfit-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Fitting a linear model, <strong><em>default</em></strong> is treated as a quantitative response variable</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-balance_default-scatterplot-lmfit">Figure&nbsp;4</a> shows that a linear model fails to fit the data. In particular, for low credit card balances the linear model shows a “negative probability of default”. This is quite prominent here as response variable is imbalanced towards the No default category. For the same reasons, the least square method fails to correctly fit the category of interest (less than 0.25 probability).</p>
<p>Usually in such presentation (for example <span class="citation" data-cites="hosmer2013">Hosmer, Lemeshow, and Sturdivant (<a href="#ref-hosmer2013" role="doc-biblioref">2013</a>)</span>) data is more balanced and a linear model approximately fits the two classes. However in any case a linear model cannot confine the predicted value to <span class="math inline">\([0, 1]\)</span> for all observations of predictors.</p>
</section>
<section id="a-more-formal-definition" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="a-more-formal-definition"><span class="header-section-number">1.2</span> A more formal definition</h2>
<p>We use the concepts we have defined in the first part of this lesson. The problem we are facing trying to predict the output default (<span class="math inline">\(Y \in(0,1)\)</span>) using a training set of inputs or featur vector <span class="math inline">\(X\)</span> is a binary classification problem.</p>
<p>We remind that to estimate an optimal classifier for output <span class="math inline">\(Y \in \{0,1\}\)</span> using input <span class="math inline">\(X = (X_1,\cdots,X_p)\)</span> one approach was to:</p>
<ul>
<li><p>model the joint distribution (or generative distribution) between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>,</p></li>
<li><p>estimate <span class="math inline">\(\eta(x)\)</span> with:</p></li>
</ul>
<p><span class="math display">\[
\eta(x)=\mathbb{P}[Y=1|X=x)] = \mathbb{E}[Y=1|X=x)]
\]</span></p>
<ul>
<li><p><span class="math inline">\(\eta(x)\)</span> can be used as a Scoring function (ROC curve, choice of cutoff <span class="math inline">\(s\)</span>)</p></li>
<li><p>and we can use the classifier (usually <span class="math inline">\(s=\frac{1}{2}\)</span>) to predict output <span class="math inline">\(Y\)</span>:</p></li>
</ul>
<p><span class="math display">\[
f_s(x)=\left\{ \begin{array}{ll}
    1 &amp;  \mbox{if } \eta(x)\geq s\cr
    0 &amp;  \mbox{otherwise}\cr
\end{array} \right.
\]</span></p>
<p>In the case of <strong>Logistic Regression</strong> classifier, we model:</p>
<p><span class="math display">\[
Y|X=x~ \sim B(\eta(x))
\]</span></p>
<p>with</p>
<p><span class="math display">\[
\eta(x)=\sigma(x^T\beta) =\frac{exp(x^T\beta)}{1+exp(x^T\beta)}
\]</span></p>
<p>for some parameter <span class="math inline">\(\beta=(\beta_1,\cdots,\beta_p)\in \mathbb R^p\)</span>, usually <span class="math inline">\(x_1=1\)</span> and <span class="math inline">\(\beta_1\)</span> is an intercept. <span class="math inline">\(\sigma\)</span> is the sigmoid logistic function we have seen before.</p>
<p>In the literature is usual to denote <span class="math inline">\(\eta(X)=p_{\beta}(X)\)</span> or <span class="math inline">\(\eta(X)=\pi_{\beta}(X)\)</span>.</p>
<p>From now, we will use the notation <span class="math inline">\(p_{\beta}(X)\)</span>.</p>
<p>Defining <span class="math inline">\(\mathrm{logit}: x \to \log\bigg( \frac{x}{1-x}\bigg)\)</span> we have:</p>
<p><span class="math display">\[
\mathrm{logit}(p_{\beta}(X))=X^T\beta
\]</span></p>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
The <strong>Logistic Regression</strong> model:
</div>
</div>
<div class="callout-body-container callout-body">
<p>We are given <span class="math inline">\((x_i, y_i) \in \mathbb R^p \times \{0,1\}\)</span>, <span class="math inline">\(i=1,\cdots,n\)</span></p>
<p>The Logistic Regression model assumes that outputs <span class="math inline">\(y_i\)</span> are independent Bernoulli with parameter <span class="math inline">\(p_{\beta}(x_i)\)</span> depending on <span class="math inline">\(x_i\)</span>:</p>
<p><span class="math display">\[
\mathrm{logit}(p_{\beta}(x_i))=x_i^T\beta
\]</span></p>
</div>
</div>
<p>The Logistic Regression model defined above is a special case of more general family of models, the so-called Generalized Linear Models (GLM).</p>
<p>The family of GLM extends the applicability of linear-model ideas to data where responses are binary (e.g.&nbsp;Logistic Regression) or counts (e.g.&nbsp;Poisson Regression), among further possibilities. The concept emerged with Nelder and Wedderburn and has been studied extensively (see <span class="citation" data-cites="nelder1972">Nelder and Wedderburn (<a href="#ref-nelder1972" role="doc-biblioref">1972</a>)</span> or <span class="citation" data-cites="cornillon2019">Cornillon and Matzner-Løber (<a href="#ref-cornillon2019" role="doc-biblioref">2019</a>)</span>) .</p>
<p>The syntax to fit the Logistic model in R using <code>glm()</code> is:</p>
<p><span class="math display">\[
\mathtt{glm(} \mathrm{y} \sim \mathrm{~x,~}\mathtt{data=}~\mathrm{dataframe,~}\mathtt{family~=~binomial(link~=~"logit")}
\]</span></p>
<p>The formula <span class="math inline">\(\mathrm{y} \sim \mathrm{x}\)</span> depicts the model (i.e.&nbsp;inputs are <span class="math inline">\(X\)</span>, output is <span class="math inline">\(Y\)</span>) and the <code>data=</code> argument points to the training set contained in a R dataframe (or tibble). This is quite similar to the <code>lm()</code> function.</p>
<p>We also need to specify the distribution for the conditional <span class="math inline">\(Y\)</span> values (binomial) and the link function (logit) via the <code>family=</code> argument.</p>
<p>For our example:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>glm_default <span class="ot">&lt;-</span> <span class="fu">glm</span>(default <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> student <span class="sc">+</span> balance <span class="sc">+</span> income,</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> default_data,</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>                   <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">"logit"</span>))</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>glm_default <span class="ot">&lt;-</span> <span class="fu">glm</span>(default <span class="sc">~</span> .,</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> default_data,</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>                   <span class="at">family =</span> <span class="st">"binomial"</span>) <span class="co"># by default: link = "logit"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The command <code>summary</code> produces result summaries of the fitted model:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(glm_default)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = default ~ ., family = "binomial", data = default_data)

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -1.087e+01  4.923e-01 -22.080  &lt; 2e-16 ***
studentYes  -6.468e-01  2.363e-01  -2.738  0.00619 ** 
balance      5.737e-03  2.319e-04  24.738  &lt; 2e-16 ***
income       3.033e-06  8.203e-06   0.370  0.71152    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2920.6  on 9999  degrees of freedom
Residual deviance: 1571.5  on 9996  degrees of freedom
AIC: 1579.5

Number of Fisher Scoring iterations: 8</code></pre>
</div>
</div>
<p>We will see later how to interpret or understand what is printed</p>
<p>A coefficient-wise output of the model can be obtained as a <code>tibble</code> using <code>tidy()</code> from package <code>broom</code>:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>broom<span class="sc">::</span><span class="fu">tidy</span>(glm_default)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">

<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":["term"],"name":[1],"type":["chr"],"align":["left"]},{"label":["estimate"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["std.error"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["statistic"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p.value"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"(Intercept)","2":"-1.086905e+01","3":"4.922555e-01","4":"-22.080088","5":"4.911280e-108"},{"1":"studentYes","2":"-6.467758e-01","3":"2.362525e-01","4":"-2.737646","5":"6.188063e-03"},{"1":"balance","2":"5.736505e-03","3":"2.318945e-04","4":"24.737563","5":"4.219578e-135"},{"1":"income","2":"3.033450e-06","3":"8.202615e-06","4":"0.369815","5":"7.115203e-01"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<p>Based on this output, the fitted model is (we have re-scaled balance and income for better readability):</p>
<p><span class="math display">\[
\log \bigg( \frac{p_{\beta}(x_i)}{1 - p_{\beta}(x_i)}\bigg) = -1.08 - 0.65(\mathbb{1}_{\mathrm{student}_i=\mathrm{Yes}}) + 5.74(\frac{\mathrm{balance}_i}{1000})+ 0.03(\frac{\mathrm{income}_i}{10000})
\]</span></p>
</section>
<section id="estimation" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="estimation"><span class="header-section-number">1.3</span> Estimation</h2>
<section id="maximum-likelihood-estimation" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="maximum-likelihood-estimation"><span class="header-section-number">1.3.1</span> Maximum Likelihood Estimation</h3>
<p>We are given <span class="math inline">\((x_i, y_i) \in \mathbb R^p \times \{0,1\}\)</span>, <span class="math inline">\(i=1,\cdots,n\)</span> where outputs <span class="math inline">\(y_i\)</span> are independent Bernoulli with parameter <span class="math inline">\(p_{\beta}(x_i)\)</span> depending on <span class="math inline">\(x_i\)</span>:</p>
<p><span class="math display">\[
\mathrm{logit}(p_{\beta}(x_i))=x_i^T\beta
\]</span></p>
<p>The parameters <span class="math inline">\(\beta\)</span> of the Logistic Regression model are usually determined using Maximum Likelihood Estimation (MLE). It consists on finding <span class="math inline">\(\beta\)</span> for which the joint probability of the observed data is greatest.</p>
<p>As <span class="math inline">\(y_i\)</span> are independent the likelihood function (joint probability) is the product of the probability mass functions:</p>
<p><span class="math display">\[
L(Y,\beta) = \prod_{i=1}^n p_{\beta}(x_i)^{y_i}(1-p_{\beta}(x_i))^{1-y_i}
\]</span></p>
<p>with <span class="math inline">\(Y=(y_1,\cdots,y_n)\)</span> and <span class="math inline">\(\beta=(\beta_1,\cdots,\beta_p)\)</span>.</p>
<p>We seek to maximize the likelihood function over <span class="math inline">\(\beta\)</span>, it is equivalent but easier to maximize the log-likelihood:</p>
<p><span class="math display">\[
\begin{align}
\ell(Y,\beta)=\log L(Y,\beta) &amp;=\sum_{i=1}^n \left(y_i \log(p_{\beta}(x_i))+(1-y_i) \log(1- p_{\beta}(x_i))\right) \\
                              &amp;=\sum_{i=1}^{n} \left(y_i \log(\frac{p_{\beta}(x_i)}{1-p_{\beta}(x_i)})+\log(1- p_{\beta}(x_i))\right)\\
                              &amp;=\sum_{i=1}^{n} \left(y_i x_i^T\beta -\log(1 + \exp(x_i^T\beta)\right)
\end{align}
\]</span></p>
<p>If the MLE <span class="math inline">\(\hat\beta\)</span> exists, the gradient of log-likelihood satisfies (first order necessary condition):</p>
<p><span class="math display">\[
\nabla\ell(Y,\beta)=\left(\frac{\partial \ell(Y,\beta)}{\partial \beta_1}, \cdots,\frac{\partial \ell(Y,\beta)}{\partial \beta_p}\right)=\mathbf 0
\]</span></p>
<p>We have for <span class="math inline">\(j=1,\cdots,p\)</span>:</p>
<p><span class="math display">\[
\frac{\partial \ell(Y,\beta)}{\partial \beta_j}=\sum_{i=1}^{n} \left(y_i x_{ij} -x_{ij}\frac{\exp(x_i^T\beta)}{1+\exp(x_i^T\beta)}\right)=\sum_{i=1}^{n} x_{ij} \left(y_i- p_{\beta}(x_i)\right)
\]</span></p>
<p>In vector form:</p>
<p><span class="math display">\[
\nabla\ell(Y,\beta)=\sum_{i=1}^{n} x_{i} \left(y_i- p_{\beta}(x_i)\right)=X^T(Y-P_{\beta})
\]</span></p>
<p>where:</p>
<p><span class="math display">\[
\begin{align}
X = \begin{pmatrix}
x_{11} &amp; \cdots &amp; x_{1p} \\
x_{21} &amp; \cdots &amp; x_{2p} \\
\vdots  &amp; \vdots  &amp; \vdots   \\
x_{n1} &amp; \cdots &amp; x_{np}
\end{pmatrix} =
\begin{pmatrix}
x_1^T\\
x_2^T\\
\vdots \\
x_n^T
\end{pmatrix}\in \mathbb{R}^{n\times (p)}, \quad
Y = \begin{pmatrix}
y_{1} \\
y_{2}\\
\vdots \\
y_{n}  
\end{pmatrix} \quad and \quad
P_{\beta} = \begin{pmatrix}
p_{\beta}(x_1) \\
p_{\beta}(x_2)\\
\vdots \\
p_{\beta}(x_n)  
\end{pmatrix}
\end{align}
\]</span></p>
<p>In the literature <span class="math inline">\(\nabla\ell(Y,\beta)\)</span> is denoted as the Fisher’s score function <span class="math inline">\(S(\beta)\)</span>, if the MLE <span class="math inline">\(\hat\beta\)</span> exists, we have:</p>
<p><span class="math display">\[
S(\hat\beta)=\nabla\ell(Y,\hat\beta)=X^T(Y-P_{\hat\beta})=0
\]</span></p>
<p>Solving this equation involves solving <span class="math inline">\(p\)</span> non-linear equations in <span class="math inline">\(\beta\)</span>:</p>
<p><span class="math display">\[
y_1 x_{1j} + \cdots + y_n x_{nj} = x_{1j}\frac{\exp(x_1^T\beta)}{1+\exp(x_1^T\beta)}+ \cdots + x_{nj}\frac{\exp(x_n^T\beta)}{1+\exp(x_n^T\beta)},\quad j=1,\cdots,p
\]</span></p>
</section>
<section id="numerical-methods" class="level3" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="numerical-methods"><span class="header-section-number">1.3.2</span> Numerical methods</h3>
<p>In practice we use numerical methods to solve these non-linear equations as no closed-form solution exist.</p>
<p>If we assume that <span class="math inline">\(rank(X)=p\)</span>, we will have that <span class="math inline">\(S(\beta)\)</span> is concave in <span class="math inline">\(\beta\)</span> hence if we find a local maximum it is a global maximum.</p>
<p>We have for <span class="math inline">\((k,l) \in (1,\cdots,p)^2\)</span>:</p>
<p><span class="math display">\[
\begin{align}
\frac{\partial\mathcal \ell}{\partial\beta_k\partial\beta_l}(\beta)= &amp; \frac{\partial}{\partial\beta_k}
\sum_{i=1}^nx_{il}(y_i-\frac{\exp(x_i^T\beta)}{1+\exp(x_i^T\beta)}) \\
=&amp; -\sum_{i=1}^nx_{il}x_{ik}\frac{\exp(x_i^T\beta)}{(1+\exp(x_i^T\beta))^2} \\
=&amp; -\sum_{i=1}^nx_{ik}p_\beta(x_i)(1-p_\beta(x_i))x_{il}
\end{align}
\]</span></p>
<p>We obtain that in matrix form:</p>
<p><span class="math display">\[
H(\beta)=\nabla^2\ell(Y,\beta)=-X^T W_\beta X
\]</span></p>
<p>where:</p>
<p><span class="math display">\[
\begin{align}
W_\beta = \begin{pmatrix}
p_\beta(x_1)(1-p_\beta(x_1)) &amp; \cdots &amp; \cdots\\
\vdots  &amp; \ddots &amp; \vdots \\
\cdots  &amp; \cdots &amp; p_\beta(x_n)(1-p_\beta(x_n))
\end{pmatrix}
\end{align}
\]</span></p>
<p>We have <span class="math inline">\(p_\beta(x_i)(1-p_\beta(x_i))\geq0\)</span> hence <span class="math inline">\(W(\beta)\)</span> is semi-definite negative and since <span class="math inline">\(rank(X)=p\)</span>, <span class="math inline">\(H(\beta)\)</span> is concave.</p>
<p>It is shown in <span class="citation" data-cites="albert1984a">(<a href="#ref-albert1984a" role="doc-biblioref">Albert and Aanderson 1984</a>)</span> that if additionally there is no complete separation in the training set: <img src="images/unique_mle.png" class="img-fluid" data-fig-align="center"></p>
<p>then the MLE exists and is unique.</p>
<section id="the-newton-raphson-ie-fisher-scoring-method" class="level4" data-number="1.3.2.1">
<h4 data-number="1.3.2.1" class="anchored" data-anchor-id="the-newton-raphson-ie-fisher-scoring-method"><span class="header-section-number">1.3.2.1</span> The Newton-Raphson (ie Fisher Scoring) method</h4>
<p>In practice the Newton-Raphson method is used to solve the equation:</p>
<p><span class="math display">\[
S(\beta)=\nabla\ell(Y,\beta)=X^T(Y-P_{\beta})=0
\]</span></p>
<p>Using Taylor expansion of Score <span class="math inline">\(S(\beta)\)</span>:</p>
<p><span class="math display">\[
S(\hat\beta) \approx S(\beta^{(k)})+H(\beta^{(k)})(\hat\beta-\beta^{(k)})
\]</span> and starting from an initial guess of <span class="math inline">\(\beta=\beta_0\)</span>, the Newton-Raphson update formula is:</p>
<p><span class="math display">\[
\beta^{(k+1)} = \beta^{(k)} - H^{-1}(\beta^{(k)})S(\beta^{(k)})
\]</span></p>
<p>We show below a naive implementation of Newton-Raphson method to estimate <span class="math inline">\(\beta\)</span> (also known as Fisher Scoring algorithm in the context of Logistic Regression)</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We put the data frame in matrix form</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co"># also adding an intercept</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">rep</span>(<span class="dv">1</span>, <span class="fu">nrow</span>(default_data)),</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>                          <span class="fu">as.matrix</span>(default_data <span class="sc">%&gt;%</span> <span class="fu">select</span>(balance, income))) </span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(X) <span class="ot">&lt;-</span>  <span class="fu">c</span>(<span class="st">"(Intercept)"</span>, <span class="st">"balance"</span>, <span class="st">"income"</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(X)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co"># We extract the output as vector</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> default_data <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">default =</span> <span class="fu">if_else</span>(default<span class="sc">==</span><span class="st">'Yes'</span>, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="sc">%&gt;%</span> <span class="fu">pull</span>(default)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co"># We set an initial guess for beta and criterion for stopping</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.01</span>, <span class="fl">0.0</span>, <span class="fl">0.0</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>nb_iter <span class="ot">&lt;-</span> <span class="dv">25</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>tol <span class="ot">&lt;-</span> <span class="fl">1e-4</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>lr_solve <span class="ot">&lt;-</span> <span class="cf">function</span>(X, Y, beta, nb_iter, tol){</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nb_iter){</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># first compute p_beta(X)</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>        p_beta <span class="ot">&lt;-</span> <span class="fu">exp</span>(X <span class="sc">%*%</span> beta) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(X <span class="sc">%*%</span> beta))</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># then the Score</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>        Score_beta <span class="ot">&lt;-</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> (Y<span class="sc">-</span>p_beta)</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># and the Hessian</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>        W_beta <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, n, n)</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>        <span class="fu">diag</span>(W_beta) <span class="ot">&lt;-</span> p_beta<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p_beta)</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>        Hessian_beta <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fu">t</span>(X) <span class="sc">%*%</span> W_beta <span class="sc">%*%</span> X</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># we update beta</span></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>        new_beta <span class="ot">&lt;-</span> beta <span class="sc">-</span> <span class="fu">solve</span>(Hessian_beta) <span class="sc">%*%</span> Score_beta</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># we check for convergence</span></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(<span class="fu">t</span>(beta<span class="sc">-</span>new_beta) <span class="sc">%*%</span> (beta<span class="sc">-</span>new_beta) <span class="sc">&lt;</span> tol){</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>            <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">beta =</span> beta, <span class="at">hessian =</span> Hessian_beta, <span class="at">nb_iter =</span> i)) </span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>        beta <span class="ot">&lt;-</span> new_beta</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">beta =</span> beta, <span class="at">hessian =</span> Hessian_beta, <span class="at">nb_iter =</span> i)) </span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>sol <span class="ot">&lt;-</span> <span class="fu">lr_solve</span>(X, Y, beta, nb_iter, tol)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We verify that R <code>glm()</code> and our algorithm give the same coefficients:</p>
<ul>
<li>Newton-Raphson:</li>
</ul>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">round</span>(<span class="fu">t</span>(sol<span class="sc">$</span>beta),<span class="dv">6</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>     (Intercept)  balance  income
[1,]   -11.53791 0.005646 2.1e-05</code></pre>
</div>
</div>
<ul>
<li>R <code>glm()</code>:</li>
</ul>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>glm_bal_inc <span class="ot">&lt;-</span> <span class="fu">glm</span>(default <span class="sc">~</span> balance <span class="sc">+</span> income,</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data =</span> default_data,</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family =</span> <span class="st">"binomial"</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">round</span>(<span class="fu">coef</span>(glm_bal_inc ),<span class="dv">6</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)     balance      income 
 -11.540468    0.005647    0.000021 </code></pre>
</div>
</div>
<p>In the next sections (Interpretation, Confidence intervals, Tests) we will try to understand the outputs of the <code>glm()</code> function from a statistical viewpoint.</p>
</section>
<section id="the-iterative-reweighted-least-square-irls-method" class="level4" data-number="1.3.2.2">
<h4 data-number="1.3.2.2" class="anchored" data-anchor-id="the-iterative-reweighted-least-square-irls-method"><span class="header-section-number">1.3.2.2</span> The Iterative Reweighted Least Square (IRLS) method</h4>
<p>There is an equivalent approach to the the Newton-Raphson described in the literature as Iterative Reweighted Least Square (IRLS).</p>
<p>The Newton-Raphson update formula rewrites:</p>
<p><span class="math display">\[
\begin{align}
\beta^{(k+1)} &amp;= \beta^{(k)} - H^{-1}(\beta^{(k)})S(\beta^{(k)}) \\
&amp;=\beta^{(k)} + (X^TW_{\beta^{(k)}}X)^{-1}X^T(Y-P_{\beta^{(k)}}) \\
&amp;= (X^TW_{\beta^{(k)}}X)^{-1}(X^TW_{\beta^{(k)}}X)\beta^{(k)} + (X^TW_{\beta^{(k)}}X)^{-1}X^T(Y-P_{\beta^{(k)}}) \\
&amp;= (X^TW_{\beta^{(k)}}X)^{-1}X^TW_{\beta^{(k)}}\left(X\beta^{(k)}+W_{\beta^{(k)}}^{-1}(Y-P_{\beta^{(k)}}) \right) \\
&amp;= (X^TW_{\beta^{(k)}}X)^{-1}X^TW_{\beta^{(k)}}Z_{\beta^{(k)}} \\
\end{align}
\]</span></p>
<p>where:</p>
<p><span class="math display">\[
Z_{\beta^{(k)}}= X\beta^{(k)}+W_{\beta^{(k)}}^{-1}(Y-P_{\beta^{(k)}})
\]</span></p>
<p><span class="math inline">\(\beta^{(k+1)} = (X^TW_{\beta^{(k)}}X)^{-1}X^TW_{\beta^{(k)}}Z_{\beta{(k)}}\)</span> corresponds to the solution of a weighted (<span class="math inline">\(W_{\beta^{(k)}}\)</span>) linear regression of <span class="math inline">\(Z_{\beta^{(k)}}\)</span> by <span class="math inline">\(X\)</span>. As an exercise you can implement this algorithm.</p>
</section>
<section id="example-where-mle-is-not-finite" class="level4" data-number="1.3.2.3">
<h4 data-number="1.3.2.3" class="anchored" data-anchor-id="example-where-mle-is-not-finite"><span class="header-section-number">1.3.2.3</span> Example where MLE is not finite</h4>
<p>To conclude on the numerical aspects, we signal a special and extreme case where the iterative algorithm won’t converge. The theoretical aspect is covered in <span class="citation" data-cites="albert1984a">(<a href="#ref-albert1984a" role="doc-biblioref">Albert and Aanderson 1984</a>)</span>.</p>
<p>We simulate a perfectly separated data set. Here <span class="math inline">\(X\in \mathbb [-1,1]\)</span> and <span class="math inline">\(Y\in\{0,1\}\)</span>:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1987</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">runif</span>(<span class="at">n =</span> <span class="dv">50</span>, <span class="at">min =</span> <span class="sc">-</span><span class="dv">1</span>, <span class="at">max =</span> <span class="dv">0</span>),</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>       <span class="fu">runif</span>(<span class="at">n =</span> <span class="dv">50</span>, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">1</span>))</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">50</span>))</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>tbl_separated <span class="ot">&lt;-</span> <span class="fu">tibble</span>(X,Y)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(tbl_separated) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="fu">aes</span>(X, Y))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="Logistic_Regression_wo_solutions_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>In this setting the iterative algorithm fails to converge and coefficient “saturates” to a high/low value (while it should go to infinite):</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>glm_separated <span class="ot">&lt;-</span> <span class="fu">glm</span>(Y <span class="sc">~</span> X,</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">data =</span> tbl_separated,</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">family=</span><span class="st">"binomial"</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>glm_separated<span class="sc">$</span>coef</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)           X 
  -5.763399 4227.385776 </code></pre>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>separated_fit <span class="ot">&lt;-</span> broom<span class="sc">::</span><span class="fu">augment</span>(glm_separated, <span class="at">type.predict =</span> <span class="st">"response"</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(separated_fit) <span class="sc">+</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="fu">aes</span>(X, Y)) <span class="sc">+</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="fu">aes</span>(X,.fitted))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="Logistic_Regression_wo_solutions_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Now we slightly modify the data set, changing a <span class="math inline">\(y\)</span> observation with <span class="math inline">\(x\in[-1,0]\)</span> from <span class="math inline">\(0\)</span> to <span class="math inline">\(1\)</span>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>Y1 <span class="ot">&lt;-</span> Y</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>Y1[<span class="dv">25</span>] <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>tbl_overlap <span class="ot">&lt;-</span> <span class="fu">tibble</span>(X,Y1)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(tbl_overlap) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="fu">aes</span>(X, Y1))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="Logistic_Regression_wo_solutions_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The iterative algorithm converges again and the impact on the Scoring function (i.e.&nbsp;<span class="math inline">\(\mathbb{P}[Y=1|X=x)\)</span>) and the decision rule (shifting left below <span class="math inline">\(X=O\)</span>) is not negligible for a one point change:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>glm_overlap <span class="ot">&lt;-</span> <span class="fu">glm</span>(Y1 <span class="sc">~</span> X,</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">data =</span> tbl_separated,</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">family=</span><span class="st">"binomial"</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>overlap_fit <span class="ot">&lt;-</span> broom<span class="sc">::</span><span class="fu">augment</span>(glm_overlap, <span class="at">type.predict =</span> <span class="st">"response"</span>)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(overlap_fit) <span class="sc">+</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="fu">aes</span>(X, Y1)) <span class="sc">+</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="fu">aes</span>(X,.fitted))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="Logistic_Regression_wo_solutions_files/figure-html/unnamed-chunk-20-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Nonetheless the case we described is very unlikely to happen in a real life setting, and a good data set exploration should avoid such trap. More details can be found in the document <code>Separation and Convergence Issues in Logistic Regression.pdf</code></p>
</section>
</section>
<section id="logistic-regression-as-a-machine-learning-approach" class="level3" data-number="1.3.3">
<h3 data-number="1.3.3" class="anchored" data-anchor-id="logistic-regression-as-a-machine-learning-approach"><span class="header-section-number">1.3.3</span> Logistic Regression as a machine learning approach</h3>
<p>We have another look at the log-likelihood equation stated before, we have:</p>
<p><span class="math display">\[
\begin{align}
\ell(Y,\beta)=\log L(Y,\beta) &amp;=\sum_{i=1}^n \left(y_i \log(p_{\beta}(x_i))+(1-y_i) \log(1- p_{\beta}(x_i))\right) \\
                              &amp;=-\sum_{i=1}^{n} \ell_{logistic} \left(p_{\beta}(x_i),y_i\right) \\
                              &amp;= -n\hat{\mathrm R}(p_\beta)
\end{align}
\]</span></p>
<p>where <span class="math inline">\(\ell_{logistic}: \{0,1\}\times \{0,1\} \to \mathbb R^+\)</span>:</p>
<p><span class="math display">\[
\ell_{logistic}(y,z) = -y\log(z)-(1-y)\log(1-z)=\left\{ \begin{array}{ll}
    -\log(z) &amp;  \mbox{if } y = 1\cr
    -\log(1-z) &amp;  \mbox{if } y = 0\cr
\end{array} \right.
\]</span></p>
<p>and <span class="math inline">\(\hat{\mathrm{R}}(p_\beta)\)</span> is the empirical risk on the training set.</p>
<p>Estimating <span class="math inline">\(\beta\)</span> by maximizing the log-likelihood is equivalent to minimizing with respect to <span class="math inline">\(\beta\)</span> the empirical risk of <span class="math inline">\(p_\beta\)</span> for the logistic loss. Note that usually in the context of machine learning and logistic loss, the output <span class="math inline">\(Y\)</span> is relabeled to <span class="math inline">\(\{-1,1\}\)</span></p>
</section>
</section>
</section>
<section id="interpretation" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Interpretation</h1>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(glm_default)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = default ~ ., family = "binomial", data = default_data)

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -1.087e+01  4.923e-01 -22.080  &lt; 2e-16 ***
studentYes  -6.468e-01  2.363e-01  -2.738  0.00619 ** 
balance      5.737e-03  2.319e-04  24.738  &lt; 2e-16 ***
income       3.033e-06  8.203e-06   0.370  0.71152    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2920.6  on 9999  degrees of freedom
Residual deviance: 1571.5  on 9996  degrees of freedom
AIC: 1579.5

Number of Fisher Scoring iterations: 8</code></pre>
</div>
</div>
<p>Based on this output, the fitted model is (we have re-scaled balance and income for better readability):</p>
<p><span class="math display">\[
\log \bigg( \frac{p_{\beta}(x_i)}{1 - p_{\beta}(x_i)}\bigg) = -1.08 - 0.65(\mathbb{1}_{\mathrm{student}_i=\mathrm{Yes}}) + 5.74(\frac{\mathrm{balance}_i}{1000})+ 0.03(\frac{\mathrm{income}_i}{10000})
\]</span></p>
<section id="coefficients" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="coefficients"><span class="header-section-number">2.1</span> Coefficients</h2>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>We cannot interpret the coefficients in the same manner as we interpret coefficients from a linear model, as the outcome is now expressed in “logits”:</p>
<ul>
<li>The predicted logit (or as we will see later log-odds) of defaulting for non-students with zero balance and income are <span class="math inline">\(-1.08\)</span>.</li>
<li>Each one-unit difference in <span class="math inline">\(\frac{\mathrm{balance}}{1000}\)</span> is associated with a difference of 5.74 in the predicted logit of defaulting.</li>
<li>Each one-unit difference in <span class="math inline">\(\frac{\mathrm{income}}{10000}\)</span> is associated with a difference of 0.03 in the predicted logit of defaulting.</li>
</ul>
</div>
</div>
</section>
<section id="odds" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="odds"><span class="header-section-number">2.2</span> Odds</h2>
<p>We remind the following relationship:</p>
<p><span class="math display">\[
\mathrm{logit}(p_{\beta}(x))=\log(\frac{p_{\beta}(x)}{1-p_{\beta}(x)})=x^T\beta
\]</span></p>
<p>The ratio on which we take the logarithm is called odds:</p>
<p><span class="math display">\[
odd_\beta(x) = \frac{p_{\beta}(x)}{1-p_{\beta}(x)}=exp(x^T\beta)
\]</span></p>
<p>It represents the chance an event occurs (<span class="math inline">\(p_{\beta}(x)\)</span>) versus the chance that same event does not occur (<span class="math inline">\(1-p_{\beta}(x)\)</span>).</p>
<p>Odds are an alternative scale to probability for representing chance.</p>
<p>They arose as a way to express the payoffs for bets. An even bet means that the winner gets paid an equal amount to that staked.</p>
<p>A 3–1 against bet would pay <span class="math inline">\(\$3\)</span> for every <span class="math inline">\(\$1\)</span> bet, while a 3–1 on bet would pay only <span class="math inline">\(\$1\)</span> for every <span class="math inline">\(\$3\)</span> bet.</p>
<p>For an event <span class="math inline">\(A\)</span> we have <span class="math inline">\(odds(A) \in [0,+\infty[\)</span>, and <span class="math inline">\(odds(A) &gt; 1\)</span> if <span class="math inline">\(\mathbf P(A) &gt; 0.5\)</span>.</p>
<p>Example: <span class="math inline">\(P(A)= \frac{3}{5}\)</span> is equivalent to <span class="math inline">\(Odds(A) = 1.5\)</span>. It means <span class="math inline">\(A\)</span> happens 1.5 more often than its complement Not <span class="math inline">\(A\)</span>.</p>
<p>We can also rewrite:</p>
<p><span class="math display">\[
p_\beta(x) = \frac{odds_{\beta}(x)}{1+odds_{\beta}(x)}
\]</span> To set these ideas, for a variable <span class="math inline">\(x\)</span> in <span class="math inline">\([-5,5]\)</span>, we plot the logistic curve (i.e.&nbsp;the probabilities) together with the odds and the logits (ie log(odds)):</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create w values and transformed values</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>data_logistic <span class="ot">=</span> <span class="fu">tibble</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="sc">-</span><span class="dv">5</span>, <span class="at">to =</span> <span class="dv">5</span>, <span class="at">by =</span> <span class="fl">0.01</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>                  <span class="fu">mutate</span>(<span class="at">probs =</span> <span class="fu">exp</span>(x) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(x)), <span class="co"># logistic curve</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>                         <span class="at">odds =</span> probs <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> probs),</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>                         <span class="at">logits =</span> <span class="fu">log</span>(odds))</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="co"># View data</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Logistic curve / sigmoid (probabilities)</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span>  <span class="fu">ggplot</span>(<span class="at">data =</span> data_logistic , <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> probs)) <span class="sc">+</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>() <span class="sc">+</span></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Probabilities"</span>)</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Exponential curve (odds)</span></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span>  <span class="fu">ggplot</span>(<span class="at">data =</span> data_logistic , <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> odds)) <span class="sc">+</span></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>() <span class="sc">+</span></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Odds"</span>)</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear curve (log-odds)</span></span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span>  <span class="fu">ggplot</span>(<span class="at">data =</span> data_logistic, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> logits)) <span class="sc">+</span></span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>() <span class="sc">+</span></span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Logits=log(Odds)"</span>)</span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>p1 <span class="sc">+</span> p2 <span class="sc">+</span> p3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="Logistic_Regression_wo_solutions_files/figure-html/unnamed-chunk-22-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Interpret the coefficients in terms of odds:</p>
<ul>
<li>The coefficient of balance is 0.005737. Hence an increase of balance by 1000 points increases odds for default by a factor of 310.</li>
<li>The coefficient of income is 3^{-6}. Hence an increase of income by 10000 points increases odds for default by a factor of 1.03.</li>
<li>The coefficient of “being a student” is -0.647. Hence being a student decreases odds for default by a factor of 0.52.</li>
</ul>
</div>
</div>
</section>
<section id="odds-ratio" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="odds-ratio"><span class="header-section-number">2.3</span> Odds ratio</h2>
<p>For two observations <span class="math inline">\(x\)</span> and <span class="math inline">\(\tilde{x}\)</span> we define odds ratio as:</p>
<p><span class="math display">\[
OR(x,\tilde{x})=\frac{odds(x)}{odds(\tilde{x})}
\]</span> Odds ratio are used to compare probabilities between two observations:</p>
<ul>
<li><span class="math inline">\(OR(x,\tilde{x}) = 1 \Leftrightarrow p(x)=p(\tilde{x})\)</span></li>
<li><span class="math inline">\(OR &gt; 1 \Leftrightarrow p(x)&gt;p(\tilde{x})\)</span></li>
<li><span class="math inline">\(OR &lt; 1 \Leftrightarrow p(x)&lt;p(\tilde{x})\)</span></li>
</ul>
<p>They are also used to measure the impact of a predictor:</p>
<p><span class="math display">\[
OR(x,\tilde{x})=\exp(\beta_1(x_1-\tilde{x_1}))\cdots exp(\beta_p(x_p-\tilde{x_p}))
\]</span> Choosing <span class="math inline">\((x,\tilde{x})\)</span> differing by only one predictor <span class="math inline">\(x_j\)</span>:</p>
<p><span class="math display">\[
OR(x,\tilde{x})=\exp(\beta_j(x_j-\tilde{x_j}))
\]</span></p>
<p>In other words, <span class="math inline">\(exp(\beta_j)\)</span> is the odds ratio associated with a one-unit increase in the <span class="math inline">\(x_j\)</span>.</p>
<p>More on odds ratio interpretation can be found <a href="https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/">here</a>.</p>
</section>
</section>
<section id="inference" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Inference</h1>
<section id="asymptotic-properties-of-mle" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="asymptotic-properties-of-mle"><span class="header-section-number">3.1</span> Asymptotic properties of MLE</h2>
<p>It can be proven that under certain assumptions (see for example <span class="citation" data-cites="gourieroux1981">Gourieroux (<a href="#ref-gourieroux1981" role="doc-biblioref">1981</a>)</span> or <span class="citation" data-cites="fahrmeir1986">Fahrmeir (<a href="#ref-fahrmeir1986" role="doc-biblioref">1986</a>)</span>), the Maximum Likelihood Estimator has the following asymptotic properties:</p>
<p><span class="math display">\[
\hat\beta \xrightarrow[] {p} \beta \textrm{, as n} \to \infty
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\sqrt n(\hat\beta-\beta) \xrightarrow[]{\mathcal L} \mathcal N(0,\mathcal I(\beta)^{-1})\textrm{, as n} \to \infty
\]</span> where:</p>
<p><span class="math display">\[
\mathcal I(\beta) = -\mathbb{E}[\nabla^2\ell(Y,\beta)]=-\frac{1}{n}\nabla^2\ell(Y,\beta)=\frac{1}{n}X^T W_\beta X
\]</span></p>
<p>where <span class="math inline">\(\mathcal I(\beta)\)</span> is the Fisher information matrix. In the case of Logistic Regression, Fisher information matrix equals the Observed information matrix.</p>
<p>The asymptotic property rewrites:</p>
<p><span class="math display">\[
(\hat\beta-\beta)^Tn\mathcal I(\beta)(\hat\beta-\beta) \xrightarrow[]{\mathcal L} \chi_p^2
\]</span></p>
<p>As <span class="math inline">\(\mathcal I(\beta)\)</span> is unknown we use instead <span class="math inline">\(\mathcal I(\hat\beta)=\frac{1}{n}X^T W_\hat\beta X\)</span>. Since <span class="math inline">\(\hat\beta \xrightarrow[] {p} \beta\)</span> and <span class="math inline">\(p_\beta\)</span> continuous in <span class="math inline">\(\beta\)</span> it can be shown that:</p>
<p><span class="math display">\[
(\hat\beta-\beta)^TX^T W_{\hat\beta} X(\hat\beta-\beta) \xrightarrow[]{\mathcal L} \chi_p^2
\]</span></p>
<p>Or equivalently:</p>
<p><span class="math display">\[
\hat\beta -\beta \xrightarrow[]{\mathcal L} \mathcal N(0,\mathcal ( X^T W_{\hat\beta} X )^{-1})
\]</span></p>
</section>
<section id="wald-statistics" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="wald-statistics"><span class="header-section-number">3.2</span> Wald statistics</h2>
<section id="confidence-intervals" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="confidence-intervals"><span class="header-section-number">3.2.1</span> Confidence intervals</h3>
<p>Using the preceding asymptotic properties we can derive confidence interval and tests for the coefficients <span class="math inline">\(\beta_j\)</span>, <span class="math inline">\(j =1,\cdots,p\)</span> of the model:</p>
<p><span class="math display">\[
\frac{\hat\beta_j-\beta_j}{\hat \sigma_j} \xrightarrow[]{\mathcal L} \mathcal N(0,1)
\]</span> where <span class="math inline">\(\hat \sigma_j^2= s.e.(\hat\beta_j)^2\)</span> denotes the <span class="math inline">\(j-th\)</span> term of <span class="math inline">\(( X^T W_{\hat\beta} X )^{-1}\)</span> diagonal.</p>
<p>The typical formula for a <span class="math inline">\(1-\alpha\)</span> confidence interval is:</p>
<p><span class="math display">\[
\hat\beta_j \pm z_{1-\alpha/2} \hat \sigma_j
\]</span> where <span class="math inline">\(z_{1-\alpha/2}\)</span> is the <span class="math inline">\((1-\alpha/2)\)</span> quantile of the standard normal distribution.</p>
<p>Going further, the asymptotic properties of MLE also allow to test the “statistical significance” of each coefficient in the model, the Wald test.</p>
<p>Denoting: <span class="math inline">\(\textrm{H}_0\textrm{: } \beta_j=0\)</span> and <span class="math inline">\(\textrm{H}_1\textrm{: } \beta_j \neq 0\)</span> we have under <span class="math inline">\(\textrm{H}_0\)</span>:</p>
<p><span class="math display">\[
\frac{\hat\beta_j}{\hat \sigma_j} \xrightarrow[]{\mathcal L} \mathcal N(0,1)
\]</span> We will reject <span class="math inline">\(\textrm{H}_0\)</span> at level <span class="math inline">\(\alpha\)</span> if the absolute of the observed value <span class="math inline">\(\frac{\hat\beta_j}{\hat \sigma_j}\)</span> (denoted in <code>glm</code> output as <code>z value</code>) is above the <span class="math inline">\((1-\alpha/2)\)</span> quantile of the standard normal distribution.</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>glm_bal_inc <span class="ot">&lt;-</span> <span class="fu">glm</span>(default <span class="sc">~</span> balance <span class="sc">+</span> income,</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data =</span> default_data,</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family =</span> <span class="st">"binomial"</span>)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(glm_bal_inc)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = default ~ balance + income, family = "binomial", 
    data = default_data)

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -1.154e+01  4.348e-01 -26.545  &lt; 2e-16 ***
balance      5.647e-03  2.274e-04  24.836  &lt; 2e-16 ***
income       2.081e-05  4.985e-06   4.174 2.99e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2920.6  on 9999  degrees of freedom
Residual deviance: 1579.0  on 9997  degrees of freedom
AIC: 1585

Number of Fisher Scoring iterations: 8</code></pre>
</div>
</div>
<p>Said differently, we reject <span class="math inline">\(\textrm{H}_0\)</span> at level <span class="math inline">\(\alpha\)</span> when <span class="math inline">\(p = \mathbf P(|z|&gt;|\frac{\hat\beta_j}{\hat \sigma_j}|)&lt;\alpha\)</span>.</p>
<p><span class="math inline">\(p\)</span> is called the p-value.</p>
<p>The output of <code>glm</code> in <code>R</code> shows:</p>
<ul>
<li><p><span class="math inline">\(\hat\beta_j\)</span> as <code>Estimate</code>,</p></li>
<li><p><span class="math inline">\(\hat \sigma_j\)</span> as <code>Std. Error</code>,</p></li>
<li><p>the absolute of the observed test statistic <span class="math inline">\(\frac{\hat\beta_j}{\hat \sigma_j}\)</span> as <code>z value</code>,</p></li>
<li><p>and the p-value as <code>Pr(&gt;|z|)</code></p></li>
</ul>
<p>We obtain the <code>z value</code> using estimate and its standard deviation:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>z <span class="ot">&lt;-</span> glm_bal_inc<span class="sc">$</span>coefficients[<span class="dv">3</span>] <span class="sc">/</span> (<span class="fu">summary</span>(glm_bal_inc))<span class="sc">$</span>coefficients[<span class="dv">3</span>,<span class="dv">2</span>]</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>z</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>  income 
4.174178 </code></pre>
</div>
</div>
<p>and then the p-value:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>(<span class="dv">1</span><span class="sc">-</span><span class="fu">pnorm</span>(z))<span class="sc">*</span><span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>      income 
2.990638e-05 </code></pre>
</div>
</div>
<p>Using the hessian matrix obtained before as a side product of the Newton-Raphson algorithm, we retrieve comparable values with <code>glm</code> outputs for <span class="math inline">\(\hat \sigma_j\)</span>:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>std_errors <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">solve</span>(<span class="sc">-</span><span class="fu">as.matrix</span>(sol<span class="sc">$</span>hessian))))</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>std_errors</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> (Intercept)      balance       income 
4.346349e-01 2.273110e-04 4.984579e-06 </code></pre>
</div>
</div>
<p>The <code>R</code> command to get confidence interval of estimators based on Wald statistic is the following (by default <span class="math inline">\(\alpha=5\%\)</span>)</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint.default</span>(glm_bal_inc)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>                    2.5 %        97.5 %
(Intercept) -1.239258e+01 -1.068836e+01
balance      5.201460e-03  6.092746e-03
income       1.103823e-05  3.057972e-05</code></pre>
</div>
</div>
<p>We can retrieve it manually using coefficient estimate and standard deviation:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>output_bal_inc <span class="ot">=</span> <span class="fu">summary</span>(glm_bal_inc)<span class="sc">$</span>coefficients</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>bal_std_estimate <span class="ot">&lt;-</span> output_bal_inc[<span class="dv">2</span>,<span class="dv">1</span>]</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>bal_std_error <span class="ot">&lt;-</span> output_bal_inc[<span class="dv">2</span>,<span class="dv">2</span>]</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="co"># upper bound for beta(balance) at 5%</span></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>upper <span class="ot">&lt;-</span> bal_std_estimate <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> bal_std_error</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="co"># lower bound for beta(balance) at 5%</span></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>lower <span class="ot">&lt;-</span> bal_std_estimate <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> bal_std_error</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>(bal_confint <span class="ot">&lt;-</span> <span class="fu">c</span>(lower, upper))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.005201452 0.006092754</code></pre>
</div>
</div>
<p>The following <code>R</code> command provides confidence interval of estimators using a more advance profile likelihood method:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(glm_bal_inc)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>                    2.5 %        97.5 %
(Intercept) -1.241910e+01 -1.071361e+01
balance      5.214030e-03  6.105971e-03
income       1.105359e-05  3.060844e-05</code></pre>
</div>
</div>
<p>More details on profile likelihood method can be found <a href="https://stats.stackexchange.com/questions/5304/why-is-there-a-difference-between-manually-calculating-a-logistic-regression-95">here</a>.</p>
</section>
<section id="tests-on-model-coefficients" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="tests-on-model-coefficients"><span class="header-section-number">3.2.2</span> Tests on model coefficients</h3>
<p>Based on the same idea, it is possible to test for the nullity of a subset of the model coefficients.</p>
<p>Denoting: <span class="math inline">\(\textrm{H}_0\textrm{: } \beta_1=\cdots=\beta_q=0\)</span>, <span class="math inline">\(\textrm{H}_1\textrm{: } \exists j \in \{1,\cdots,q \} \textrm{ }|\textrm{ }\beta_j \neq 0\)</span>, <span class="math inline">\(\hat\beta=(\hat\beta_1,\cdots,\hat\beta_p)\)</span> the MLE and <span class="math inline">\(\hat\beta_{1:q}=(\hat\beta_1,\cdots,\hat\beta_q)\)</span> the vector of first <span class="math inline">\(q\)</span> parameters.</p>
<p>We have under <span class="math inline">\(\textrm{H}_0\)</span>:</p>
<p><span class="math display">\[
\hat\beta_{1:q}^T( X^T W_{\hat\beta} X )^{-1}_{1:q}\hat\beta_{1:q} \xrightarrow[]{\mathcal L} \chi_q^2
\]</span> where <span class="math inline">\((X^T W_{\hat\beta} X )^{-1}_{1:q}\)</span> is the <span class="math inline">\(q \times q\)</span> upper left block matrix extracted from the inverse of hessian.</p>
<p>We will reject <span class="math inline">\(\textrm{H}_0\)</span> at level <span class="math inline">\(\alpha\)</span> if the observed value <span class="math inline">\(\hat\beta_{1:q}^T( X^T W_{\hat\beta} X )^{-1}_{1:q}\hat\beta_{1:q}\)</span> is above the <span class="math inline">\(1-\alpha\)</span> quantile of the <span class="math inline">\(\chi_q^2\)</span> distribution.</p>
<p>We show below the Wald tests for each coefficient in the model using <code>summary</code>:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(glm_default)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = default ~ ., family = "binomial", data = default_data)

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -1.087e+01  4.923e-01 -22.080  &lt; 2e-16 ***
studentYes  -6.468e-01  2.363e-01  -2.738  0.00619 ** 
balance      5.737e-03  2.319e-04  24.738  &lt; 2e-16 ***
income       3.033e-06  8.203e-06   0.370  0.71152    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2920.6  on 9999  degrees of freedom
Residual deviance: 1571.5  on 9996  degrees of freedom
AIC: 1579.5

Number of Fisher Scoring iterations: 8</code></pre>
</div>
</div>
<p>These tests can be also performed in <code>R</code> using <code>car::Anova</code> or <code>aod::wald.test</code> routines. In particular when categorical variables have more than two levels these functions allow to test each variables as a whole (vs coefficient by coefficient when using <code>summary</code>)</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">Anova</span>(glm_default, <span class="at">type=</span><span class="dv">3</span>, <span class="at">test.statistic=</span> <span class="st">"Wald"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">

<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Df"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["Chisq"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Pr(>Chisq)"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"1","2":"487.5302944","3":"4.911280e-108","_rn_":"(Intercept)"},{"1":"1","2":"7.4947060","3":"6.188063e-03","_rn_":"student"},{"1":"1","2":"611.9470216","3":"4.219578e-135","_rn_":"balance"},{"1":"1","2":"0.1367631","3":"7.115203e-01","_rn_":"income"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<p>We can retrieve these outputs manually:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>sum_default <span class="ot">&lt;-</span> <span class="fu">summary</span>(glm_default)</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>beta_income <span class="ot">&lt;-</span> sum_default<span class="sc">$</span>coefficients[<span class="dv">4</span>,<span class="dv">1</span>]</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>stdev_income <span class="ot">&lt;-</span> sum_default<span class="sc">$</span>coefficients[<span class="dv">4</span>,<span class="dv">2</span>]</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>wald <span class="ot">&lt;-</span> beta_income <span class="sc">^</span> <span class="dv">2</span> <span class="sc">/</span> stdev_income <span class="sc">^</span> <span class="dv">2</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span><span class="fu">pchisq</span>(wald, <span class="at">df =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.7115203</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>z_val <span class="ot">&lt;-</span> sum_default<span class="sc">$</span>coefficients[<span class="dv">4</span>,<span class="dv">3</span>]</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">pnorm</span>(<span class="fu">abs</span>(z_val)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.7115203</code></pre>
</div>
</div>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Testing the income coefficient (Terms = 4)</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>aod<span class="sc">::</span><span class="fu">wald.test</span>(<span class="at">b =</span> <span class="fu">coef</span>(glm_default), <span class="at">Sigma =</span> <span class="fu">vcov</span>(glm_default), <span class="at">Terms =</span> <span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Wald test:
----------

Chi-squared test:
X2 = 0.14, df = 1, P(&gt; X2) = 0.71</code></pre>
</div>
</div>
<p>With all routines, the p-value for the income coefficient is <span class="math inline">\(0.71\)</span> validating the null hypothesis.</p>
<p>Using <code>Terms</code> or <code>L</code> parameters in <code>aod::wald.test</code> it is also feasible to test the null hypothesis for a subsets of parameters:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Testing the income coefficient (Terms = 4)</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>aod<span class="sc">::</span><span class="fu">wald.test</span>(<span class="at">b =</span> <span class="fu">coef</span>(glm_default), <span class="at">Sigma =</span> <span class="fu">vcov</span>(glm_default), <span class="at">Terms =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Wald test:
----------

Chi-squared test:
X2 = 698.3, df = 3, P(&gt; X2) = 0.0</code></pre>
</div>
</div>
<p>The null hypothesis is rejected for the model with balance and student.</p>
<p>There are known issues with the Wald test:</p>
<ul>
<li><p>It is not invariant to re-reparametrisation. In the case of logistic regression we have a nonlinear model where the individual parameters are not of foremost interest, but rather odds ratios for instance, which are nonlinear transforms of the parameters.</p></li>
<li><p>Hauck and Donner (1977) have shown that the Wald test has undesirable properties for logistic regression. In particular when <span class="math inline">\(\hat \beta_j \to \infty\)</span> (e.g.&nbsp;in case of separation or quasi separation), it is likely that <span class="math inline">\(\hat\sigma_j\to \infty\)</span>. The result can be that the Wald statistic tends to zero as the distance between the parameter estimate and the null value increases (null hypothesis gets more and more wrong).</p></li>
</ul>
<p>So in the context of Logistic Regression (and GLM), while Wald statistics are usually reported by statistical routines, the likelihood ratio or deviance-based tests are often favored.</p>
</section>
</section>
<section id="likelihood-ratio-tests" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="likelihood-ratio-tests"><span class="header-section-number">3.3</span> Likelihood ratio tests</h2>
<p>It is possible to test for the nullity of a subset of the model coefficients using Likelihood Ratio statistics.</p>
<p>Denoting: <span class="math inline">\(\textrm{H}_0\textrm{: } \beta_1=\cdots=\beta_q=0\)</span>, <span class="math inline">\(\textrm{H}_1\textrm{: } \exists j \in \{1,\cdots,q \} \textrm{ }|\textrm{ }\beta_j \neq 0\)</span>, and <span class="math inline">\(\hat\beta=(\hat\beta_1,\cdots,\hat\beta_p)\)</span> the MLE, we have under <span class="math inline">\(\textrm{H}_0\)</span>:</p>
<p><span class="math display">\[
-2\left(\ell_{\textrm{H}_0}(Y,\hat\beta_{\textrm{H}_0})-\ell(Y,\hat\beta)\right)\xrightarrow[]{\mathcal L} \chi_q^2
\]</span> where <span class="math inline">\(\ell_{\textrm{H}_0}(Y,\hat\beta_{\textrm{H}_0})\)</span> is the log-likelihood of:</p>
<p><span class="math display">\[
\mathrm{logit}(p_{\beta}(X))=x_{q+1}\beta_{q+1}+\cdots+x_{n}\beta_{n}
\]</span></p>
<p>Consider two models, a larger model with <span class="math inline">\(l\)</span> parameters and likelihood <span class="math inline">\(L_L\)</span> and a smaller model with <span class="math inline">\(s\)</span> parameters and likelihood <span class="math inline">\(L_S\)</span>, where the smaller model represents a subset of the larger model. Typically the smaller model is equivalent to the large model where we have imposed:</p>
<p><span class="math display">\[
\textrm{H}_0\textrm{: } \ \beta_j = \ldots  = \beta_{j+r}  = 0
\]</span> Likelihood Ratio tests on variables may be performed in <code>R</code> using <code>car::Anova</code>:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">Anova</span>(glm_default, <span class="at">type=</span><span class="dv">3</span>, <span class="at">test.statistic=</span> <span class="st">"LR"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">

<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["LR Chisq"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["Df"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Pr(>Chisq)"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"7.4214426","2":"1","3":"6.445112e-03","_rn_":"student"},{"1":"1335.9509861","2":"1","3":"1.740402e-292","_rn_":"balance"},{"1":"0.1367695","2":"1","3":"7.115139e-01","_rn_":"income"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<p>Using base <code>R</code> <code>anova</code> it is also possible to test subsets of variables and in particular individual variables within the “full” model:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>glm_wo_student <span class="ot">&lt;-</span> <span class="fu">glm</span>(default <span class="sc">~</span> balance <span class="sc">+</span> income,</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data =</span> default_data,</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family =</span> <span class="st">"binomial"</span>)</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>glm_wo_balance <span class="ot">&lt;-</span> <span class="fu">glm</span>(default <span class="sc">~</span> student <span class="sc">+</span> income,</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data =</span> default_data,</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family =</span> <span class="st">"binomial"</span>)</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>glm_wo_income <span class="ot">&lt;-</span> <span class="fu">glm</span>(default <span class="sc">~</span> student <span class="sc">+</span> balance,</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data =</span> default_data,</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family =</span> <span class="st">"binomial"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(glm_wo_student, glm_default, <span class="at">test =</span> <span class="st">"LRT"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">

<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Resid. Df"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["Resid. Dev"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Df"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["Deviance"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["Pr(>Chi)"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"9997","2":"1578.966","3":"NA","4":"NA","5":"NA","_rn_":"1"},{"1":"9996","2":"1571.545","3":"1","4":"7.421443","5":"0.006445112","_rn_":"2"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<p>We can retrieve this result manually:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>LRT <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (<span class="fu">logLik</span>(glm_default)<span class="sc">-</span><span class="fu">logLik</span>(glm_wo_student))</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pchisq</span>(LRT, <span class="at">df =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>'log Lik.' 0.006445112 (df=4)</code></pre>
</div>
</div>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(glm_wo_balance, glm_default, <span class="at">test =</span> <span class="st">"LRT"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">

<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Resid. Df"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["Resid. Dev"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Df"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["Deviance"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["Pr(>Chi)"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"9997","2":"2907.496","3":"NA","4":"NA","5":"NA","_rn_":"1"},{"1":"9996","2":"1571.545","3":"1","4":"1335.951","5":"1.740402e-292","_rn_":"2"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(glm_wo_income, glm_default, <span class="at">test =</span> <span class="st">"LRT"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">

<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Resid. Df"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["Resid. Dev"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Df"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["Deviance"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["Pr(>Chi)"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"9997","2":"1571.682","3":"NA","4":"NA","5":"NA","_rn_":"1"},{"1":"9996","2":"1571.545","3":"1","4":"0.1367695","5":"0.7115139","_rn_":"2"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
</div>
<p>The deviance defined as <span class="math inline">\(D=-2 \ell\)</span> is often reported by statistical software in place of log-likelihood. A large likelihood corresponding to a small deviance.</p>
<p>A better coverage of tests in the context of Logistic Regression can be found <a href="https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faqhow-are-the-likelihood-ratio-wald-and-lagrange-multiplier-score-tests-different-andor-similar/">here</a> or in <span class="citation" data-cites="hosmer2013">(<a href="#ref-hosmer2013" role="doc-biblioref">Hosmer, Lemeshow, and Sturdivant 2013</a>)</span>. See also <a href="https://stats.oarc.ucla.edu/r/dae/logit-regression/">here</a> for a data analysis using <code>R</code> and see the question <a href="https://stats.stackexchange.com/questions/86351/interpretation-of-rs-output-for-binomial-regression">here</a> for a very detailed description of the outputs of <code>glm()</code> (in particular this <a href="https://stats.stackexchange.com/a/86375">answer</a>).</p>
</section>
<section id="goodness-of-fit-test-calibration" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="goodness-of-fit-test-calibration"><span class="header-section-number">3.4</span> Goodness of Fit test / Calibration</h2>
<p>Although it is generally not recommended by practitioners and theoreticians, the Hosmer &amp; Lemeshow test (see <a href="https://en.wikipedia.org/wiki/Hosmer–Lemeshow_test">here</a>, <a href="https://stats.stackexchange.com/questions/169438/evaluating-logistic-regression-and-interpretation-of-hosmer-lemeshow-goodness-of">here</a> or <a href="https://stats.stackexchange.com/a/18772">here</a>) allows to quickly assess the “goodness of fit” of a Logistic Regression.</p>
<p>But more than the test in itself, the underlying motivation is interesting: the Logistic Regression model provides an estimate of the probability of an outcome (success/failure, here the default is success or 1). The estimated probability of this outcome should be close to the true observed probability.</p>
<p>The Hosmer &amp; Lemeshow test assess if observed event rates match expected event rates in subgroups of “similar” observations. Models for which expected and observed event rates agree on these subgroups are considered well calibrated.</p>
<p>A first step of the test is to order the predicted probabilities of the outcome and divide it into Q groups (usually using deciles, Q=10).</p>
<p>Then the average predicted probability for each group is computed and compared to the observed probability.</p>
<p>The Hosmer &amp; Lemeshow test statistic <span class="math inline">\(H\)</span> is compared to a <span class="math inline">\(\chi_{Q-2}^2\)</span> distribution:</p>
<p><span class="math display">\[H=\sum_{q=1}^{Q}\frac{(o_{q}-m_{q}\mu_{q})^2}{m_{q}\mu_{q}(1-\mu_{q})} \]</span> where: - <span class="math inline">\(o_q\)</span> denotes the number of success (<span class="math inline">\(Y=1\)</span>) observed in group <span class="math inline">\(q\)</span>, - <span class="math inline">\(\mu_q\)</span> denotes the mean of <span class="math inline">\(p_{\hat\beta}(x_i)\)</span> in group <span class="math inline">\(q\)</span>, - <span class="math inline">\(m_q\)</span> denotes the number of observations in group <span class="math inline">\(q\)</span>, so that <span class="math inline">\({m_{q}\mu_{q}\)</span> is the expected number of success in group <span class="math inline">\(q\)</span>.</p>
<p>The null hypothesis is that observed/expected outcomes are close along all subgroups.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmtoolbox)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hltest</span>(glm_default)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
   The Hosmer-Lemeshow goodness-of-fit test

 Group Size Observed     Expected
     1 1000        0   0.02653992
     2 1000        0   0.10737240
     3 1000        0   0.29143249
     4 1000        1   0.67265778
     5 1000        2   1.39515666
     6 1000        1   2.87108745
     7 1000        7   5.98948667
     8 1000       16  13.74542953
     9 1000       45  39.52811751
    10 1000      261 268.37271994

         Statistic =  3.68229 
degrees of freedom =  8 
           p-value =  0.88459 </code></pre>
</div>
</div>
<p>Here the p-value for a chi-squared statistic of <span class="math inline">\(H=3.68\)</span> with <span class="math inline">\(df=Q-2=8\)</span> is <span class="math inline">\(p=0.885\)</span> which is well above the usual levels (eg <span class="math inline">\(0.05\)</span>), so that the null hypothesis is accepted, goodness of fit is acceptable.</p>
<p>However the Hosmer &amp; Lemeshow test is dependent on the choice of Q and the binning performed on probabilities and is sometimes considered unreliable.</p>
<p>Nonetheless it is usual to assess or diagnose the good calibration of a model probabilities using Calibration Plots or Probability Calibration Curves (see here for a <a href="https://www.tidyverse.org/blog/2022/11/model-calibration/">recent R package from the tidyverse/tidymodel ecosystem</a> and here for a <a href="https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html">scikit-learn version</a>): they are used to visualize if predictions are consistent with the observed event rates (be it on the training set or a testing set, which is better). For example considering the <code>default</code> data set we have:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>check_default_prob <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(<span class="fu">cbind</span>(<span class="at">fitted=</span>glm_default<span class="sc">$</span>fitted.values,</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>                                      <span class="at">Y =</span> default_data <span class="sc">%&gt;%</span></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>                                        <span class="fu">mutate</span>(<span class="at">default =</span> <span class="fu">if_else</span>(default <span class="sc">==</span> <span class="st">"Yes"</span>, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>                                        <span class="fu">pull</span>(default)))</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>(calibration_data <span class="ot">&lt;-</span> check_default_prob <span class="sc">%&gt;%</span></span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">bins_prob =</span> <span class="fu">cut</span>(fitted, <span class="at">breaks =</span> <span class="fu">quantile</span>(fitted,<span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.10</span>)), <span class="at">include.lowest =</span> <span class="cn">TRUE</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(bins_prob) <span class="sc">%&gt;%</span></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">n =</span> <span class="fu">n</span>(),</span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>            <span class="at">def =</span> <span class="fu">sum</span>(Y),</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a>            <span class="at">no_def =</span> n <span class="sc">-</span> def,  </span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a>            <span class="at">predict_prob =</span> <span class="fu">mean</span>(fitted),</span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a>            <span class="at">real_prob =</span> def<span class="sc">/</span>n,</span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a>            <span class="at">forecast_acc =</span> def <span class="sc">/</span> <span class="fu">sum</span>(check_default_prob<span class="sc">$</span>Y)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">

<div data-pagedtable="false">
  <script data-pagedtable-source="" type="application/json">
{"columns":[{"label":["bins_prob"],"name":[1],"type":["fct"],"align":["left"]},{"label":["n"],"name":[2],"type":["int"],"align":["right"]},{"label":["def"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["no_def"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["predict_prob"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["real_prob"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["forecast_acc"],"name":[7],"type":["dbl"],"align":["right"]}],"data":[{"1":"[1.03e-05,5.14e-05]","2":"1000","3":"0","4":"1000","5":"2.653992e-05","6":"0.000","7":"0.000000000"},{"1":"(5.14e-05,0.000176]","2":"1000","3":"0","4":"1000","5":"1.073724e-04","6":"0.000","7":"0.000000000"},{"1":"(0.000176,0.000443]","2":"1000","3":"0","4":"1000","5":"2.914325e-04","6":"0.000","7":"0.000000000"},{"1":"(0.000443,0.000945]","2":"1000","3":"1","4":"999","5":"6.726578e-04","6":"0.001","7":"0.003003003"},{"1":"(0.000945,0.00197]","2":"1000","3":"2","4":"998","5":"1.395157e-03","6":"0.002","7":"0.006006006"},{"1":"(0.00197,0.00402]","2":"1000","3":"1","4":"999","5":"2.871087e-03","6":"0.001","7":"0.003003003"},{"1":"(0.00402,0.0088]","2":"1000","3":"7","4":"993","5":"5.989487e-03","6":"0.007","7":"0.021021021"},{"1":"(0.0088,0.021]","2":"1000","3":"16","4":"984","5":"1.374543e-02","6":"0.016","7":"0.048048048"},{"1":"(0.021,0.0709]","2":"1000","3":"45","4":"955","5":"3.952812e-02","6":"0.045","7":"0.135135135"},{"1":"(0.0709,0.978]","2":"1000","3":"261","4":"739","5":"2.683727e-01","6":"0.261","7":"0.783783784"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>(calib_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(calibration_data, <span class="fu">aes</span>(<span class="at">x =</span> predict_prob, <span class="at">y =</span> real_prob)) <span class="sc">+</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="Logistic_Regression_wo_solutions_files/figure-html/unnamed-chunk-42-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>calib_plot <span class="sc">+</span> <span class="fu">coord_cartesian</span>(<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.05</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.05</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="Logistic_Regression_wo_solutions_files/figure-html/unnamed-chunk-43-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>calib_plot <span class="sc">+</span> <span class="fu">coord_cartesian</span>(<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.005</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.005</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="Logistic_Regression_wo_solutions_files/figure-html/unnamed-chunk-44-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The model tends to slightly overestimate/underestimates some deciles without a clear pattern.</p>
</section>
</section>
<section id="variable-selection-model-assessment" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Variable selection, model assessment</h1>
<p>We have seen in the last section how to compare two or more nested Logistic regression models (typically a reduced model with less variables than a reference or full model).</p>
<p>Real life data sets usually contain a large number of predictors or inputs. As their number grow, the analyst will have to analyse a growing number of possible models or variable combinations (typically <span class="math inline">\(2^p\)</span> where <span class="math inline">\(p\)</span> denotes the number of predictors). Furthermore as the number of predictors grow the models might overfit the training set, causing a deterioration of prediction error.</p>
<p>Variable selection is a critical aspect of building Logistic Regression models and prediction models in general. This process seeks a balance between the bias-variance trade-off, aiming to find models that are both parsimonious and predictive. Parsimony, in this context, implies the selection of a minimal set of predictor variables that still provides an accurate representation of the data, avoiding overfitting while enhancing model generalization.</p>
<p>This is a complex subject that we will not cover in depth in this course.</p>
<p>For a better coverage, chapter 7 <code>Model Assessment and Selection</code> of <span class="citation" data-cites="hastie2009">Hastie, Tibshirani, and Friedman (<a href="#ref-hastie2009" role="doc-biblioref">2009</a>)</span> discusses in depth the interplay between bias, variance and model complexity, in a general setting. Chapter 6 <code>Linear Model Selection and Regularization</code> of <span class="citation" data-cites="islr2021">James et al. (<a href="#ref-islr2021" role="doc-biblioref">2021</a>)</span> discusses methods to automatically perform variable selection in the context of linear models.</p>
<p>Various methods and criteria are employed for variable selection. In this section we consider some methods for selecting subsets of predictors: this include best subset, stepwise model selection procedures and penalization or shrinkage. We use the Agriculture Farm Lending data set as an example.</p>
<section id="best-subset" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="best-subset"><span class="header-section-number">4.1</span> Best subset</h2>
<p>One common approach is the “best subset” method, which evaluates all possible combinations of predictor variables, resulting in <span class="math inline">\(2^p-1\)</span> models for p predictors, and selects the one that optimizes a specified criterion, such as the Akaike Information Criterion (AIC) or Bayesian Information Criterion (BIC). It is computationally intensive and usually restricted to low dimension data sets.</p>
<hr>
<p><strong>Algorithm</strong>: Best subset selection</p>
<hr>
<ol type="1">
<li>For <span class="math inline">\(k=1,\cdots,p\)</span>:
<ol type="a">
<li>Fit all <span class="math inline">\({p\choose k}\)</span> models that contain exactly <span class="math inline">\(k\)</span> predictors.</li>
<li>Pick the best among these <span class="math inline">\({p\choose k}\)</span> models, and call it <span class="math inline">\(\mathcal M_k\)</span>. In the case of Logistic Regression, best usually means largest log-likelihood or min deviance.</li>
</ol></li>
<li>Select a single best model from among <span class="math inline">\(\mathcal M_1,\cdots,\mathcal M_p\)</span> using a criterion. Usually the prediction error on a validation set, AIC, BIC…</li>
</ol>
<hr>
<p>Given <span class="math inline">\(|\mathcal M|\)</span> we define the two following criteria which represent two way of penalizing the maximised log-likelihood <span class="math inline">\(\ell(Y,\hat\beta)\)</span>:</p>
<p><span class="math display">\[
\textrm{AIC}(\mathcal M)=-2\ell(Y,\hat\beta)+2|\mathcal M|
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\textrm{BIC}(\mathcal M)=-2\ell(Y,\hat\beta)+|\mathcal M|\log(n)
\]</span> The package <code>bestglm</code> allows best subset selection up to roughly <span class="math inline">\(15\)</span> variables, by default it uses BIC. We use the Default data set to illustrate because Agriculture Farm Lending has around <span class="math inline">\(30\)</span> variables:</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(bestglm)</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>default_best <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(default_data <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">Y=</span><span class="fu">if_else</span>(default<span class="sc">==</span><span class="st">'Yes'</span>, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>default))</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a><span class="co"># p must be &lt; 15 for GLM</span></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Error in bestglm(as.data.frame(don_desbois_quanti), family = binomial) :</span></span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a><span class="co"># p = 22. must be &lt;= 15 for GLM.</span></span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>mod_sel <span class="ot">&lt;-</span> <span class="fu">bestglm</span>(default_best, <span class="at">family =</span> binomial)</span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a>mod_sel</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>BIC
BICq equivalent for q in (0.000417890560228229, 0.989405669357382)
Best Model:
                 Estimate  Std. Error    z value      Pr(&gt;|z|)
(Intercept) -10.749495878 0.369191361 -29.116326 2.230782e-186
studentYes   -0.714877620 0.147519010  -4.846003  1.259734e-06
balance       0.005738104 0.000231847  24.749526 3.136911e-135</code></pre>
</div>
</div>
</section>
<section id="stepwise-logistic-regression" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="stepwise-logistic-regression"><span class="header-section-number">4.2</span> Stepwise Logistic Regression</h2>
<p>Alternatively, stepwise methods, including forward and backward selection, iteratively add or remove variables based on the chosen criterion. These approaches, while useful, can be also computationally intensive, especially for high-dimensional datasets.</p>
<hr>
<p><strong>Algorithm</strong>: Forward stepwise selection</p>
<hr>
<ol type="1">
<li>For <span class="math inline">\(k=1,\cdots,p\)</span>:
<ol type="a">
<li>Consider all <span class="math inline">\(p+1-k\)</span> models that augment the predictors in <span class="math inline">\(\mathcal M_k\)</span> with one additional predictor.</li>
<li>Pick the best among these <span class="math inline">\(p+1-k\)</span> models, and call it <span class="math inline">\(\mathcal M_{k+1}\)</span>. In the case of Logistic Regression, best usually means largest log-likelihood or min deviance.</li>
</ol></li>
<li>Select a single best model from among <span class="math inline">\(\mathcal M_1,\cdots,\mathcal M_p\)</span> using a criterion. Usually the prediction error on a validation set, AIC, BIC…</li>
</ol>
<hr>
<p>or</p>
<hr>
<p><strong>Algorithm</strong>: Backward stepwise selection</p>
<hr>
<ol type="1">
<li>Let <span class="math inline">\(\mathcal M_p\)</span> denote the full model, which contains all <span class="math inline">\(p\)</span> predictors.</li>
<li>For <span class="math inline">\(k=p,\cdots,1\)</span>:
<ol type="a">
<li>Consider all <span class="math inline">\(k\)</span> models that contain all but one of the predictors in <span class="math inline">\(\mathcal M_k\)</span>, for a total of <span class="math inline">\(k-1\)</span> predictors.</li>
<li>Pick the best among these <span class="math inline">\(k\)</span> models, and call it <span class="math inline">\(\mathcal M_{k-1}\)</span>. In the case of Logistic Regression, best usually means largest log-likelihood or min deviance.</li>
</ol></li>
<li>Select a single best model from among <span class="math inline">\(\mathcal M_1,\cdots,\mathcal M_p\)</span> using a criterion. Usually the prediction error on a validation set, AIC, BIC…</li>
</ol>
<hr>
<p>Additionally versions mixing forward and backward stepwise selection exist. For example adding variables to the model sequentially, in the same way as forward selection then at each step the method tries remove variables that no longer provide a significant improvement in the model fit.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co">#define intercept-only model</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>intercept_only <span class="ot">&lt;-</span> <span class="fu">glm</span>(Y <span class="sc">~</span> <span class="dv">1</span>, </span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>                      <span class="at">data=</span>default_data <span class="sc">%&gt;%</span></span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>                      <span class="fu">mutate</span>(<span class="at">Y=</span><span class="fu">if_else</span>(default<span class="sc">==</span><span class="st">'Yes'</span>, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a>                      <span class="fu">select</span>(<span class="sc">-</span>default), <span class="at">family=</span><span class="st">"binomial"</span>)</span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a><span class="co">#define model with all predictors</span></span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a>all <span class="ot">&lt;-</span> <span class="fu">glm</span>(Y <span class="sc">~</span> ., </span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a>            <span class="at">data=</span>default_data <span class="sc">%&gt;%</span></span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a>            <span class="fu">mutate</span>(<span class="at">Y=</span><span class="fu">if_else</span>(default<span class="sc">==</span><span class="st">'Yes'</span>, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a>            <span class="fu">select</span>(<span class="sc">-</span>default), <span class="at">family=</span><span class="st">"binomial"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># perform forward stepwise regression based on LRT test and AIC (k=2)</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>forward_aic <span class="ot">&lt;-</span> <span class="fu">step</span>(intercept_only, <span class="at">direction=</span><span class="st">'forward'</span>, <span class="at">test =</span> <span class="st">'LRT'</span>, <span class="at">scope=</span><span class="fu">formula</span>(all), <span class="at">k=</span><span class="dv">2</span>, <span class="at">trace =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Start:  AIC=2922.65
Y ~ 1

          Df Deviance    AIC     LRT  Pr(&gt;Chi)    
+ balance  1   1596.5 1600.5 1324.20 &lt; 2.2e-16 ***
+ student  1   2908.7 2912.7   11.97 0.0005416 ***
+ income   1   2916.7 2920.7    3.96 0.0465233 *  
&lt;none&gt;         2920.7 2922.7                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Step:  AIC=1600.45
Y ~ balance

          Df Deviance    AIC    LRT  Pr(&gt;Chi)    
+ student  1   1571.7 1577.7 24.770 6.459e-07 ***
+ income   1   1579.0 1585.0 17.485 2.895e-05 ***
&lt;none&gt;         1596.5 1600.5                     
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Step:  AIC=1577.68
Y ~ balance + student

         Df Deviance    AIC     LRT Pr(&gt;Chi)
&lt;none&gt;        1571.7 1577.7                 
+ income  1   1571.5 1579.5 0.13677   0.7115</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(forward_aic)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = Y ~ balance + student, family = "binomial", data = default_data %&gt;% 
    mutate(Y = if_else(default == "Yes", 1, 0)) %&gt;% select(-default))

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -1.075e+01  3.692e-01 -29.116  &lt; 2e-16 ***
balance      5.738e-03  2.318e-04  24.750  &lt; 2e-16 ***
studentYes  -7.149e-01  1.475e-01  -4.846 1.26e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2920.6  on 9999  degrees of freedom
Residual deviance: 1571.7  on 9997  degrees of freedom
AIC: 1577.7

Number of Fisher Scoring iterations: 8</code></pre>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># perform backward stepwise regression based on LRT test and BIC (k=log(n))</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>backward_bic <span class="ot">&lt;-</span> <span class="fu">step</span>(all, <span class="at">direction=</span><span class="st">'backward'</span>, <span class="at">test =</span> <span class="st">'LRT'</span>, <span class="at">scope=</span><span class="fu">formula</span>(all), <span class="at">k=</span><span class="fu">log</span>(<span class="fu">nrow</span>(default_data)), <span class="at">trace =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Start:  AIC=1608.39
Y ~ student + balance + income

          Df Deviance    AIC     LRT  Pr(&gt;Chi)    
- income   1   1571.7 1599.3    0.14  0.711514    
- student  1   1579.0 1606.6    7.42  0.006445 ** 
&lt;none&gt;         1571.5 1608.4                      
- balance  1   2907.5 2935.1 1335.95 &lt; 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Step:  AIC=1599.31
Y ~ student + balance

          Df Deviance    AIC     LRT  Pr(&gt;Chi)    
&lt;none&gt;         1571.7 1599.3                      
- student  1   1596.5 1614.9   24.77 6.459e-07 ***
- balance  1   2908.7 2927.1 1337.00 &lt; 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(backward_bic)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = Y ~ student + balance, family = "binomial", data = default_data %&gt;% 
    mutate(Y = if_else(default == "Yes", 1, 0)) %&gt;% select(-default))

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -1.075e+01  3.692e-01 -29.116  &lt; 2e-16 ***
studentYes  -7.149e-01  1.475e-01  -4.846 1.26e-06 ***
balance      5.738e-03  2.318e-04  24.750  &lt; 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2920.6  on 9999  degrees of freedom
Residual deviance: 1571.7  on 9997  degrees of freedom
AIC: 1577.7

Number of Fisher Scoring iterations: 8</code></pre>
</div>
</div>
</section>
<section id="introducing-penalized-logistic-regressions" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="introducing-penalized-logistic-regressions"><span class="header-section-number">4.3</span> Introducing penalized logistic regressions</h2>
<p>As an alternative, penalized regression techniques like the Lasso (Least Absolute Shrinkage and Selection Operator) or Ridge offer an efficient means of variance reduction and/or variable selection by introducing a penalty term in the Logistic Regression estimation algorithm. In particular Lasso promotes the sparsity of coefficients and automatically selects relevant predictors while shrinking others to zero.</p>
<p>We remind that to estimate Logistic Regression parameters, we maximized in <span class="math inline">\(\beta\)</span> the log-likelihood:</p>
<p><span class="math display">\[
\ell(Y,\beta)=\log L(Y,\beta) =\sum_{i=1}^n \left(y_i \log(p_{\beta}(x_i))+(1-y_i) \log(1- p_{\beta}(x_i))\right)
\]</span></p>
<p>In the context of penalized Logistic Regression the idea is to minimize in <span class="math inline">\(\beta\)</span>:</p>
<p><span class="math display">\[
-\ell(Y,\beta)+\lambda_2\lVert\beta\rVert_2 + \lambda_1\lVert\beta\rVert_1
\]</span> where <span class="math inline">\(\lambda_1, \lambda_2\)</span> are two constants.</p>
<p>The underlying idea is to constraint or shrink the size of the coefficients estimates.</p>
<p>When <span class="math inline">\(\lambda_1&gt;0, \lambda_2=0\)</span> we are using a Lasso penalty.</p>
<p>When <span class="math inline">\(\lambda_1=0, \lambda_2&gt;0\)</span> we are using a Ridge penalty.</p>
<p>When <span class="math inline">\(\lambda_1&gt;0, \lambda_2&gt;0\)</span> we are using an Elastic Net penalty.</p>
<p>Without entering to much details in this section, Ridge does a proportional shrinkage of all coefficients while Lasso tends to truncates some of the coefficients at zero. Usually the following graphs are given in textbooks/slides to give some intuition about Ridge/Lasso (the figure below is taken from the original Lasso article by Tibshirani published in 1996):</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/lasso_classic_graph.png" class="img-fluid figure-img" width="350"></p>
</figure>
</div>
<p>We use here the Mixture data set to give further intuition about Ridge/Lasso penalties:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>data_mixture_example <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"../1_Scoring_and_Logistic_Regression/data_mixture_example.rds"</span>)</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">as.numeric</span>(data_mixture_example<span class="sc">$</span>Y)<span class="sc">-</span><span class="dv">1</span></span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">as.matrix</span>(data_mixture_example <span class="sc">%&gt;%</span> <span class="fu">select</span>(x1,x2))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Ridge estimator is:</p>
<p><span class="math display">\[
\hat \beta_{ridge}=\underset{\beta}{\operatorname{argmin}}-\ell(Y,\beta)+\lambda\lVert\beta\rVert_2
\]</span> which rewrites:</p>
<p><span class="math display">\[
\hat \beta_{ridge}=\underset{\beta}{\operatorname{argmin}}-\ell(Y,\beta)
\]</span> subject to <span class="math inline">\(\lVert\beta\rVert_2 \leq t\)</span>, where <span class="math inline">\(t\)</span> maps to <span class="math inline">\(\lambda\)</span>.</p>
<p>We plot below the log-likelihood of the Logistic Regression (colored levels lines centered around the MLE) for the Mixture data set, adding the Ridge constraint (the circle in black is the boundary <span class="math inline">\(\lVert\beta\rVert_2 \leq t\)</span>) :</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>grid <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">beta_1 =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="fl">3.5</span>, <span class="fl">3.5</span>, .<span class="dv">05</span>), <span class="at">beta_2 =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="fl">3.5</span>, <span class="fl">3.5</span>, .<span class="dv">05</span>)) <span class="sc">%&gt;%</span> <span class="fu">as_tibble</span>()</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Prediction function used to classify areas on the grid and imply the decision boundary</span></span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>LL  <span class="ot">&lt;-</span> <span class="cf">function</span>(b0, b1, b2){</span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>  beta <span class="ot">&lt;-</span>  <span class="fu">c</span>(b1, b2)</span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>( <span class="fu">sum</span>(<span class="sc">-</span>y<span class="sc">*</span><span class="fu">log</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="sc">-</span>(b0<span class="sc">+</span>X<span class="sc">%*%</span>beta))) <span class="sc">-</span> </span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a>  (<span class="dv">1</span><span class="sc">-</span>y)<span class="sc">*</span><span class="fu">log</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(b0<span class="sc">+</span>X<span class="sc">%*%</span>beta))))</span>
<span id="cb77-7"><a href="#cb77-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb77-8"><a href="#cb77-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-9"><a href="#cb77-9" aria-hidden="true" tabindex="-1"></a>LL_V <span class="ot">&lt;-</span> <span class="fu">Vectorize</span>(LL)</span>
<span id="cb77-10"><a href="#cb77-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-11"><a href="#cb77-11" aria-hidden="true" tabindex="-1"></a><span class="co"># extract intercept coeff from glm (beta0 is not varying here)</span></span>
<span id="cb77-12"><a href="#cb77-12" aria-hidden="true" tabindex="-1"></a>mixture_glm <span class="ot">&lt;-</span> <span class="fu">glm</span>(Y <span class="sc">~</span> ., <span class="at">data=</span>data_mixture_example, <span class="at">family=</span><span class="st">"binomial"</span>)</span>
<span id="cb77-13"><a href="#cb77-13" aria-hidden="true" tabindex="-1"></a>beta0 <span class="ot">&lt;-</span> mixture_glm<span class="sc">$</span>coefficients[<span class="dv">1</span>]</span>
<span id="cb77-14"><a href="#cb77-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-15"><a href="#cb77-15" aria-hidden="true" tabindex="-1"></a>grid <span class="ot">&lt;-</span> grid <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">beta_0 =</span> beta0, <span class="at">LL =</span> <span class="fu">LL_V</span>(beta_0, beta_1, beta_2))</span>
<span id="cb77-16"><a href="#cb77-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-17"><a href="#cb77-17" aria-hidden="true" tabindex="-1"></a>xc <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb77-18"><a href="#cb77-18" aria-hidden="true" tabindex="-1"></a>yc <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb77-19"><a href="#cb77-19" aria-hidden="true" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fl">0.4</span></span>
<span id="cb77-20"><a href="#cb77-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-21"><a href="#cb77-21" aria-hidden="true" tabindex="-1"></a>ridge_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(grid) <span class="sc">+</span> </span>
<span id="cb77-22"><a href="#cb77-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_contour</span>(<span class="fu">aes</span>(<span class="at">x =</span> beta_1, <span class="at">y =</span> beta_2, <span class="at">z =</span> LL, <span class="at">colour =</span> <span class="fu">after_stat</span>(level)), <span class="at">binwidth =</span> <span class="dv">15</span>) <span class="sc">+</span></span>
<span id="cb77-23"><a href="#cb77-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_color_viridis_c</span>(<span class="at">option=</span><span class="st">"H"</span>) <span class="sc">+</span></span>
<span id="cb77-24"><a href="#cb77-24" aria-hidden="true" tabindex="-1"></a>    <span class="fu">annotate</span>(<span class="st">"path"</span>,</span>
<span id="cb77-25"><a href="#cb77-25" aria-hidden="true" tabindex="-1"></a>             <span class="at">x=</span>xc<span class="sc">+</span>r<span class="sc">*</span><span class="fu">cos</span>(<span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">2</span><span class="sc">*</span>pi,<span class="at">length.out=</span><span class="dv">100</span>)),</span>
<span id="cb77-26"><a href="#cb77-26" aria-hidden="true" tabindex="-1"></a>             <span class="at">y=</span>yc<span class="sc">+</span>r<span class="sc">*</span><span class="fu">sin</span>(<span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">2</span><span class="sc">*</span>pi,<span class="at">length.out=</span><span class="dv">100</span>))) <span class="sc">+</span></span>
<span id="cb77-27"><a href="#cb77-27" aria-hidden="true" tabindex="-1"></a>     <span class="fu">theme</span>(<span class="at">legend.position=</span><span class="st">"none"</span>)</span>
<span id="cb77-28"><a href="#cb77-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-29"><a href="#cb77-29" aria-hidden="true" tabindex="-1"></a>(ridge_plot <span class="sc">+</span> <span class="fu">coord_fixed</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="Logistic_Regression_wo_solutions_files/figure-html/unnamed-chunk-50-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>We obtain Ridge Logistic Regression parameters for <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span> as a function of <span class="math inline">\(\lambda\)</span>:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnetUtils) <span class="co"># convenient package allowing to use R formulas instead of glmnet sparse matrix</span></span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a>mixture_ridge <span class="ot">&lt;-</span> glmnetUtils<span class="sc">::</span><span class="fu">glmnet</span>(Y <span class="sc">~</span> ., <span class="at">data=</span>data_mixture_example, <span class="at">family=</span><span class="st">"binomial"</span>, <span class="at">alpha=</span><span class="dv">0</span>, <span class="at">lambda.min.ratio=</span><span class="fl">0.000001</span>)</span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a>ridge_result <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(<span class="fu">as.matrix</span>(<span class="fu">cbind</span>(mixture_ridge<span class="sc">$</span>lambda, mixture_ridge<span class="sc">$</span>a0, <span class="fu">t</span>(mixture_ridge<span class="sc">$</span>beta))))</span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(ridge_result) <span class="ot">&lt;-</span>  <span class="fu">c</span>(<span class="st">"lambda"</span>, <span class="st">"(Intercept)"</span>, <span class="fu">row.names</span>(mixture_ridge<span class="sc">$</span>beta))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We then visualize the Ridge Logistic Regression parameters <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\beta_2\)</span> path as <span class="math inline">\(\lambda\)</span> increases. It starts from the Logistic Regression MLE for <span class="math inline">\(\lambda=0\)</span> and it is then shrunken “uniformly” towards zero as <span class="math inline">\(\lambda\)</span> increases.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>ridge_plot <span class="sc">+</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data=</span>ridge_result, <span class="fu">aes</span>(<span class="at">x=</span>x1, <span class="at">y=</span>x2), <span class="at">alpha=</span><span class="fl">0.3</span>) <span class="sc">+</span></span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_fixed</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="Logistic_Regression_wo_solutions_files/figure-html/unnamed-chunk-52-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Exercise : implement Newton Raphson or IRLS for Ridge constraint (using either gradient/hessian of penalized likelihood or closed form solution for Linear Model with Ridge)</p>
<p>We plot below the log-likelihood of the Logistic Regression (colored levels lines centered around the MLE) for the Mixture data set, adding the Lasso constraint (the diamond/square in black is the boundary <span class="math inline">\(\lVert\beta\rVert_1 \leq t\)</span>) :</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>grid <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">beta_1 =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="fl">3.5</span>, <span class="fl">3.5</span>, .<span class="dv">05</span>), <span class="at">beta_2 =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="fl">3.5</span>, <span class="fl">3.5</span>, .<span class="dv">05</span>)) <span class="sc">%&gt;%</span> <span class="fu">as_tibble</span>()</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Prediction function used to classify areas on the grid and imply the decision boundary</span></span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a>grid <span class="ot">&lt;-</span> grid <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">beta_0 =</span> beta0, <span class="at">LL =</span> <span class="fu">LL_V</span>(beta_0, beta_1, beta_2))</span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="fl">0.4</span></span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-8"><a href="#cb80-8" aria-hidden="true" tabindex="-1"></a>lasso_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(grid) <span class="sc">+</span> </span>
<span id="cb80-9"><a href="#cb80-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_contour</span>(<span class="fu">aes</span>(<span class="at">x =</span> beta_1, <span class="at">y =</span> beta_2, <span class="at">z =</span> LL, <span class="at">colour =</span> <span class="fu">after_stat</span>(level)), <span class="at">binwidth =</span> <span class="dv">15</span>) <span class="sc">+</span></span>
<span id="cb80-10"><a href="#cb80-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_color_viridis_c</span>(<span class="at">option=</span><span class="st">"H"</span>) <span class="sc">+</span></span>
<span id="cb80-11"><a href="#cb80-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">annotate</span>(<span class="st">"segment"</span>, <span class="at">x=</span><span class="sc">-</span>h, <span class="at">xend=</span><span class="dv">0</span>, <span class="at">y=</span><span class="dv">0</span>, <span class="at">yend=</span>h, <span class="at">col =</span> <span class="st">'black'</span>) <span class="sc">+</span></span>
<span id="cb80-12"><a href="#cb80-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">annotate</span>(<span class="st">"segment"</span>, <span class="at">x=</span><span class="dv">0</span>, <span class="at">xend=</span>h, <span class="at">y=</span>h, <span class="at">yend=</span><span class="dv">0</span>, <span class="at">col =</span> <span class="st">'black'</span>) <span class="sc">+</span></span>
<span id="cb80-13"><a href="#cb80-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">annotate</span>(<span class="st">"segment"</span>, <span class="at">x=</span>h, <span class="at">xend=</span><span class="dv">0</span>, <span class="at">y=</span><span class="dv">0</span>, <span class="at">yend=</span><span class="sc">-</span>h, <span class="at">col =</span> <span class="st">'black'</span>) <span class="sc">+</span></span>
<span id="cb80-14"><a href="#cb80-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">annotate</span>(<span class="st">"segment"</span>, <span class="at">x=</span><span class="dv">0</span>, <span class="at">xend=</span><span class="sc">-</span>h, <span class="at">y=</span><span class="sc">-</span>h, <span class="at">yend=</span><span class="dv">0</span>, <span class="at">col =</span> <span class="st">'black'</span>) <span class="sc">+</span></span>
<span id="cb80-15"><a href="#cb80-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme</span>(<span class="at">legend.position=</span><span class="st">"none"</span>)</span>
<span id="cb80-16"><a href="#cb80-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-17"><a href="#cb80-17" aria-hidden="true" tabindex="-1"></a>(lasso_plot <span class="sc">+</span> <span class="fu">coord_fixed</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="Logistic_Regression_wo_solutions_files/figure-html/unnamed-chunk-54-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>We obtain Lasso Logistic Regression parameters for <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span> as a function of <span class="math inline">\(\lambda\)</span>:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>mixture_lasso <span class="ot">&lt;-</span> glmnetUtils<span class="sc">::</span><span class="fu">glmnet</span>(Y <span class="sc">~</span> ., <span class="at">data=</span>data_mixture_example, <span class="at">family=</span><span class="st">"binomial"</span>, <span class="at">alpha=</span><span class="dv">1</span>, <span class="at">lambda.min.ratio=</span><span class="fl">0.000001</span>)</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>lasso_result <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(<span class="fu">as.matrix</span>(<span class="fu">cbind</span>(mixture_lasso<span class="sc">$</span>lambda, mixture_lasso<span class="sc">$</span>a0, <span class="fu">t</span>(mixture_lasso<span class="sc">$</span>beta))))</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(lasso_result) <span class="ot">&lt;-</span>  <span class="fu">c</span>(<span class="st">"lambda"</span>, <span class="st">"(Intercept)"</span>, <span class="fu">row.names</span>(mixture_lasso<span class="sc">$</span>beta))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We then visualize the Lasso Logistic Regression parameters <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\beta_2\)</span> path as <span class="math inline">\(\lambda\)</span> increases. It starts from the Logistic Regression MLE for <span class="math inline">\(\lambda=0\)</span> and as <span class="math inline">\(\lambda\)</span> increases and at some point the solution of the constrained optimization is likely to occur at one of the corners of the diamond, which is indeed the case with the Mixture data set, the <span class="math inline">\(\beta_1\)</span> parameter being first shrunk to zero:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>lasso_plot <span class="sc">+</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data=</span>lasso_result, <span class="fu">aes</span>(<span class="at">x=</span>x1, <span class="at">y=</span>x2), <span class="at">alpha=</span><span class="fl">0.3</span>) <span class="sc">+</span></span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_fixed</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="Logistic_Regression_wo_solutions_files/figure-html/unnamed-chunk-56-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Stretching the graph a little bit to better show the Lasso path:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>lasso_plot <span class="sc">+</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data=</span>lasso_result, <span class="fu">aes</span>(<span class="at">x=</span>x1, <span class="at">y=</span>x2), <span class="at">alpha=</span><span class="fl">0.3</span>) <span class="sc">+</span></span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.5</span>, <span class="fl">0.5</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="Logistic_Regression_wo_solutions_files/figure-html/unnamed-chunk-57-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>In R the package <code>glmnet</code> implements the Lasso, Ridge and Elastic Net penalties in particular for Logistic Regression.</p>
</section>
<section id="model-assessment" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="model-assessment"><span class="header-section-number">4.4</span> Model assessment</h2>
<p>We have seen in the first lesson that in the context of statistical learning the approach was to estimate a classifier or Score with the best possible Risk or any other metric such as the AUC of a ROC curve. The final goal being to predict unobserved outputs given unobserved inputs having trained a classifier using the data at hands.</p>
<p>To assess how well the classifier or Score will “generalize” to new data, a practical approach is to split the data set into a training set and a test set or validation set. The training set being used to learn the classifier or Score, the validation set to estimate the generalization error of the classifier.</p>
<p>Two principal approaches are used: the Hold-out approach and the K-fold Cross-validation approach.</p>
<section id="hold-out-approach" class="level3" data-number="4.4.1">
<h3 data-number="4.4.1" class="anchored" data-anchor-id="hold-out-approach"><span class="header-section-number">4.4.1</span> Hold-out approach</h3>
<p>It consists in splitting the data set into:</p>
<ul>
<li>a learning or training set used to train the classifier or the Score ;</li>
<li>a validation or test set used to estimate the empirical risk of the classifier or any other metric (ROC curve, AUC).</li>
</ul>
<hr>
<p><strong>Algorithm</strong>: Hold-out approach</p>
<hr>
<ol type="1">
<li>Using a partition training/validation <span class="math inline">\(\{\mathcal T, \mathcal V\}\)</span> of the data set <span class="math inline">\(\mathcal D\)</span>:
<ol type="a">
<li>Fit the classifiers <span class="math inline">\(f_1\cdots,f_m\)</span> on <span class="math inline">\(\mathcal T\)</span></li>
<li>Compute the empirical risk <span class="math inline">\(\hat{\mathrm R}(f) = \frac{1}{n_{\mathcal V}} \sum_i \ell(y_i,f_m(x_i))\)</span> or any other metric on the validation set <span class="math inline">\(\mathcal V\)</span></li>
</ol></li>
<li>Select a single best model <span class="math inline">\(f_{m^*}\)</span> with respect to the empirical risk or metric</li>
</ol>
<hr>
<p>The main drawback using a single split of data is the possible variability of empirical risk, which is more pregnant when the data set size reduces. Against this issue an alternative approach is to repeat this process on multiple splits of the data.</p>
</section>
<section id="k-fold-cross-validation-approach" class="level3" data-number="4.4.2">
<h3 data-number="4.4.2" class="anchored" data-anchor-id="k-fold-cross-validation-approach"><span class="header-section-number">4.4.2</span> K-fold Cross-Validation approach</h3>
<p>It consists in splitting randomly the data set into <span class="math inline">\(K\)</span> blocks of folds then repeating <span class="math inline">\(K\)</span> times the Hold-out approach, each time using a different block as validation set.</p>
<hr>
<p><strong>Algorithm</strong>: K-fold Cross-Validation approach</p>
<hr>
<ol type="1">
<li>Using a random partition in <span class="math inline">\(K\)</span> blocks <span class="math inline">\(\{\mathcal D_1, \cdots,\mathcal D_K\}\)</span> of the data set <span class="math inline">\(\mathcal D\)</span></li>
<li>For <span class="math inline">\(k=1,\cdots,K\)</span>
<ol type="a">
<li><span class="math inline">\(\{\mathcal T_k, \mathcal V_k\}\)</span> with <span class="math inline">\(\mathcal V_k=\mathcal D_k\)</span> and <span class="math inline">\(\mathcal T_k=\mathcal D\setminus\mathcal D_k\)</span></li>
<li>Fit the classifiers <span class="math inline">\(f_1\cdots,f_m\)</span> on <span class="math inline">\(\mathcal T_k\)</span></li>
<li>Compute the empirical risk <span class="math inline">\(\hat{\mathrm R}(f) = \frac{1}{n_{\mathcal V_k}} \sum_i \ell(y_i,f_m(x_i))\)</span> or any other metric on the validation set <span class="math inline">\(\mathcal V_k\)</span></li>
</ol></li>
<li>Select a single best model <span class="math inline">\(f_{m^*}\)</span> using the average empirical risk or metric</li>
</ol>
<hr>
<p>A variant is to first split the data set into a training and validation set. Perform K-fold Cross-Validation on the training set, for example to select some classifier hyper parameter (number of variables or model specification in logistic regression, penalty, etc), then assess the best “optimized” models on the validation set.</p>
<p>Another variant is to repeat the K-fold CV 5 or 10 times to improve the accuracy of the estimated performance and provide and estimate on its variability.</p>
<p>This <a href="https://bradleyboehmke.github.io/HOML/process.html">book chapter</a> gives a practical overview on these methods (how to implement it in R) and also gives references discussing the validity and limitations of the methods.</p>
</section>
</section>
<section id="exercise---case-study" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="exercise---case-study"><span class="header-section-number">4.5</span> Exercise - case study</h2>
<p>The article <span class="citation" data-cites="desbois2008">Desbois (<a href="#ref-desbois2008" role="doc-biblioref">2008</a>)</span> (available <a href="https://csbigs.fr/index.php/csbigs/article/view/351">here</a> together with a sample data set) shows a complete case study around the detection of financial risks applicable to farm holdings in France. Exploratory Data Analysis is performed in particular using PCA. Linear Discriminant Analysis and Logistic Regression (plus stepwise variable selection) are used and ROC curves are used to compare the two methods.</p>
<p>The data set uses a format specific to the SPSS software, but is readable from R using the <code>foreign</code> package.</p>
<p>Using the Agriculture Farm Lending data set:</p>
<section id="eda" class="level3" data-number="4.5.1">
<h3 data-number="4.5.1" class="anchored" data-anchor-id="eda"><span class="header-section-number">4.5.1</span> EDA</h3>
<p>Explore the data set (the full case study is presented in <span class="citation" data-cites="desbois2008">Desbois (<a href="#ref-desbois2008" role="doc-biblioref">2008</a>)</span>), you might try to reproduce the PCA analysis (using package <code>FactomineR</code> for example).</p>
<div class="cell">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># package used to import spss file</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(foreign)</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>don_desbois <span class="ot">&lt;-</span> <span class="fu">read.spss</span>(<span class="st">"../data/Agriculture Farm Lending/desbois.sav"</span>,</span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>                       <span class="at">to.data.frame =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span> <span class="fu">as_tibble</span>()</span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>don_desbois <span class="ot">&lt;-</span> don_desbois <span class="sc">%&gt;%</span></span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">Y =</span> <span class="fu">as.factor</span>(<span class="fu">if_else</span>(DIFF<span class="sc">==</span><span class="st">'healthy'</span>, <span class="dv">0</span>, <span class="dv">1</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a>    dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span>DIFF)</span>
<span id="cb84-9"><a href="#cb84-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-10"><a href="#cb84-10" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(don_desbois)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 1,260
Columns: 30
$ CNTY    &lt;fct&gt; Eure, Eure, Eure, Eure, Eure, Eure, Eure, Eure, Eure, Eure, Eu…
$ STATUS  &lt;fct&gt; Entreprise individuelle, Entreprise individuelle, Entreprise i…
$ HECTARE &lt;dbl&gt; 166, 101, 138, 166, 137, 107, 100, 69, 176, 177, 108, 123, 87,…
$ ToF     &lt;fct&gt; cereals, cereals, dairy farm, cereals, mixed livestock, cereal…
$ OWNLAND &lt;fct&gt; yes, no, yes, yes, yes, yes, no, yes, yes, yes, yes, yes, yes,…
$ AGE     &lt;dbl&gt; 35, 35, 42, 50, 33, 45, 34, 30, 44, 39, 40, 40, 40, 52, 49, 44…
$ HARVEST &lt;fct&gt; 1988, 1988, 1988, 1988, 1988, 1988, 1988, 1988, 1988, 1988, 19…
$ r1      &lt;dbl&gt; 0.449, 0.450, 0.332, 0.363, 0.440, 0.306, 0.717, 0.566, 0.145,…
$ r2      &lt;dbl&gt; 0.622, 0.617, 0.819, 0.733, 0.650, 0.755, 0.320, 0.465, 0.881,…
$ r3      &lt;dbl&gt; 0.25500, 0.24110, 0.55680, 0.35960, 0.31420, 0.26350, 0.16280,…
$ r4      &lt;dbl&gt; 0.11450, 0.10840, 0.18510, 0.13050, 0.13820, 0.08055, 0.11680,…
$ r5      &lt;dbl&gt; 0.334, 0.341, 0.147, 0.232, 0.302, 0.225, 0.601, 0.499, 0.115,…
$ r6      &lt;dbl&gt; 0.785, 0.518, 0.700, 0.773, 0.846, 0.709, 0.894, 0.863, 0.439,…
$ r7      &lt;dbl&gt; 0.585, 0.393, 0.310, 0.495, 0.580, 0.523, 0.748, 0.761, 0.348,…
$ r8      &lt;dbl&gt; 0.20020, 0.12500, 0.38950, 0.27790, 0.26580, 0.18700, 0.14550,…
$ r11     &lt;dbl&gt; 0.6628, 0.7098, 0.4142, 0.4661, 0.7715, 0.8178, 0.6598, 0.6619…
$ r12     &lt;dbl&gt; 1.3698, 1.2534, 0.6370, 1.0698, 1.4752, 1.4682, 1.1018, 1.2360…
$ r14     &lt;dbl&gt; 0.23200, 0.14970, 0.48470, 0.37350, 0.25630, 0.18610, 0.18070,…
$ r17     &lt;dbl&gt; 0.0884, 0.0671, 0.0445, 0.0621, 0.0489, 0.0243, 0.0352, 0.0879…
$ r18     &lt;dbl&gt; 0.0694, 0.0348, 0.0311, 0.0480, 0.0414, 0.0173, 0.0315, 0.0758…
$ r19     &lt;dbl&gt; 0.1660, 0.1360, 0.1030, 0.1080, 0.1270, 0.0652, 0.1290, 0.2400…
$ r21     &lt;dbl&gt; 0.1340, 0.0802, 0.0890, 0.0851, 0.0838, 0.0390, 0.0784, 0.1630…
$ r22     &lt;dbl&gt; 0.3219, 0.3133, 0.2945, 0.1909, 0.2567, 0.1472, 0.3211, 0.5170…
$ r24     &lt;dbl&gt; 0.295, 0.365, 0.166, 0.265, 0.257, 0.191, 0.322, 0.305, 0.180,…
$ r28     &lt;dbl&gt; 0.475, 0.434, 0.350, 0.475, 0.475, 0.443, 0.401, 0.464, 0.475,…
$ r30     &lt;dbl&gt; 0.35000, 0.29780, 0.24680, 0.37590, 0.36690, 0.37590, 0.27240,…
$ r32     &lt;dbl&gt; 0.4313, 0.3989, 0.3187, 0.4313, 0.4313, 0.4257, 0.3697, 0.3886…
$ r36     &lt;dbl&gt; 0.886, 0.351, 1.300, 1.385, 0.886, 1.316, 0.441, 0.761, 2.147,…
$ r37     &lt;dbl&gt; 0.572, 0.867, 0.475, 0.470, 0.520, 0.431, 0.803, 0.656, 0.359,…
$ Y       &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…</code></pre>
</div>
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Variable definitions from Desbois article</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Capitalization</span></span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a><span class="co"># r1 total debt / total assets;</span></span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a><span class="co"># r2 stockholders' equity / invested capital;</span></span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a><span class="co"># r3 short term debt / total debt;</span></span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a><span class="co"># r4 short term debt / total assets;</span></span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a><span class="co"># r5 long and medium term debt / total assets;</span></span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Weight of the debt</span></span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a><span class="co"># r6 total debt / gross product;</span></span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a><span class="co"># r7 long and medium term debt / gross product;</span></span>
<span id="cb86-12"><a href="#cb86-12" aria-hidden="true" tabindex="-1"></a><span class="co"># r8 short term debt / gross product;</span></span>
<span id="cb86-13"><a href="#cb86-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-14"><a href="#cb86-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Liquidity</span></span>
<span id="cb86-15"><a href="#cb86-15" aria-hidden="true" tabindex="-1"></a><span class="co"># r11 working capital / gross product;</span></span>
<span id="cb86-16"><a href="#cb86-16" aria-hidden="true" tabindex="-1"></a><span class="co"># r12 working capital / (real inputs - financial expenses);</span></span>
<span id="cb86-17"><a href="#cb86-17" aria-hidden="true" tabindex="-1"></a><span class="co"># r14 short term debt / circulating assets;</span></span>
<span id="cb86-18"><a href="#cb86-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-19"><a href="#cb86-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Debt servicing</span></span>
<span id="cb86-20"><a href="#cb86-20" aria-hidden="true" tabindex="-1"></a><span class="co"># r17 financial expenses / total debt;</span></span>
<span id="cb86-21"><a href="#cb86-21" aria-hidden="true" tabindex="-1"></a><span class="co"># r18 financial expenses / gross product;</span></span>
<span id="cb86-22"><a href="#cb86-22" aria-hidden="true" tabindex="-1"></a><span class="co"># r19 (financial expenses+ refunding of long and</span></span>
<span id="cb86-23"><a href="#cb86-23" aria-hidden="true" tabindex="-1"></a><span class="co">#      medium term capital) / gross product;</span></span>
<span id="cb86-24"><a href="#cb86-24" aria-hidden="true" tabindex="-1"></a><span class="co"># r21 financial expenses / EBITDA;</span></span>
<span id="cb86-25"><a href="#cb86-25" aria-hidden="true" tabindex="-1"></a><span class="co"># r22 (financial expenses + refunding of long and</span></span>
<span id="cb86-26"><a href="#cb86-26" aria-hidden="true" tabindex="-1"></a><span class="co">#      medium term capital)/EBITDA;</span></span>
<span id="cb86-27"><a href="#cb86-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-28"><a href="#cb86-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Capital profitability</span></span>
<span id="cb86-29"><a href="#cb86-29" aria-hidden="true" tabindex="-1"></a><span class="co"># r24 EBITDA /total assets;</span></span>
<span id="cb86-30"><a href="#cb86-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-31"><a href="#cb86-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Earnings</span></span>
<span id="cb86-32"><a href="#cb86-32" aria-hidden="true" tabindex="-1"></a><span class="co"># r28 EBITDA / gross product;</span></span>
<span id="cb86-33"><a href="#cb86-33" aria-hidden="true" tabindex="-1"></a><span class="co"># r30 available income / gross product;</span></span>
<span id="cb86-34"><a href="#cb86-34" aria-hidden="true" tabindex="-1"></a><span class="co"># r32 (EBITDA - financial expenses) / gross product;</span></span>
<span id="cb86-35"><a href="#cb86-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-36"><a href="#cb86-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Productive activity</span></span>
<span id="cb86-37"><a href="#cb86-37" aria-hidden="true" tabindex="-1"></a><span class="co"># r36 immobilized assets / gross product;</span></span>
<span id="cb86-38"><a href="#cb86-38" aria-hidden="true" tabindex="-1"></a><span class="co"># r37 gross product / total assets.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co"># YOUR CODE HERE</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="coefficient-interpretation" class="level3" data-number="4.5.2">
<h3 data-number="4.5.2" class="anchored" data-anchor-id="coefficient-interpretation"><span class="header-section-number">4.5.2</span> Coefficient interpretation</h3>
<p>Fitting a Logistic Regression model with all variables in data set, interpret the <code>r17</code> coefficient:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="co"># YOUR CODE HERE</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="tests" class="level3" data-number="4.5.3">
<h3 data-number="4.5.3" class="anchored" data-anchor-id="tests"><span class="header-section-number">4.5.3</span> Tests</h3>
<p>Considering the model <code>Y~.</code>, is the effect of variable <code>r36</code> significant? Using Wald test. Using Likelihood Ratio Test.</p>
<p>Wald</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co"># YOUR CODE HERE</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>LRT</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co"># YOUR CODE HERE</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Hosmer &amp; Lemeshow</p>
<p>Perform a goodness of fit test and a calibration plot, compare.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># YOUR CODE HERE</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="stepwise-logistic-regression-1" class="level3" data-number="4.5.4">
<h3 data-number="4.5.4" class="anchored" data-anchor-id="stepwise-logistic-regression-1"><span class="header-section-number">4.5.4</span> Stepwise Logistic Regression</h3>
<p>Use forward stepwise selection based on the AIC criterion to select variables in the Agriculture Farm Lending data set. Compare with results from the article. (Extra, perform the same analysis using LDA/Wilks Lambda as in the aritcle).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># YOUR CODE HERE</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="penalized-logistic-regression" class="level3" data-number="4.5.5">
<h3 data-number="4.5.5" class="anchored" data-anchor-id="penalized-logistic-regression"><span class="header-section-number">4.5.5</span> Penalized Logistic Regression</h3>
<p>Perform penalized logistic regression with the Desbois data set. You can find help <a href="https://glmnet.stanford.edu/articles/glmnet.html#logistic-regression-family-binomial">here</a>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co"># YOUR CODE HERE</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="model-assessment-1" class="level3" data-number="4.5.6">
<h3 data-number="4.5.6" class="anchored" data-anchor-id="model-assessment-1"><span class="header-section-number">4.5.6</span> Model assessment</h3>
<section id="hold-out" class="level4" data-number="4.5.6.1">
<h4 data-number="4.5.6.1" class="anchored" data-anchor-id="hold-out"><span class="header-section-number">4.5.6.1</span> Hold-out</h4>
<p>Perform a simple Hold-out approach (train/test split) and evaluate ROC / AUC for some <code>glm()</code> model specification of your choice (ie choose manually a subset of variables), you might take inspiration from this <a href="https://bradleyboehmke.github.io/HOML/process.html">book chapter</a></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co"># YOUR CODE HERE</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="k-fold-cross-validation" class="level4" data-number="4.5.6.2">
<h4 data-number="4.5.6.2" class="anchored" data-anchor-id="k-fold-cross-validation"><span class="header-section-number">4.5.6.2</span> K-fold cross validation</h4>
<p>Perform k-fold cross validation and for each fold evaluate ROC / AUC for the same models as before</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="co"># YOUR CODE HERE</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
</section>
</section>
<section id="references" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-albert1984a" class="csl-entry" role="listitem">
Albert, A., and J. A. Aanderson. 1984. <span>“On the Existence of Maximum Likelihood Estimates in Logistic Regression Models.”</span> <em>Biometrika</em> 71 (1): 1–10. <a href="https://doi.org/10.1093/biomet/71.1.1">https://doi.org/10.1093/biomet/71.1.1</a>.
</div>
<div id="ref-cornillon2019" class="csl-entry" role="listitem">
Cornillon, Pierre-André, and Eric Matzner-Løber. 2019. <em>Régression Avec r, 2e Édition</em>. Springer Paris. <a href="https://doi.org/10.1007/978-2-8178-0184-1">https://doi.org/10.1007/978-2-8178-0184-1</a>.
</div>
<div id="ref-desbois2008" class="csl-entry" role="listitem">
Desbois, Dominique. 2008. <span>“<span class="nocase">Introduction to scoring methods: financial problems of farm holdings</span>.”</span> Edited by Société française de Statistique. <em><span>Case Studies in Business, Industry and Government Statistics</span></em> 2 (1): 56–76. <a href="https://hal.science/hal-01172847">https://hal.science/hal-01172847</a>.
</div>
<div id="ref-fahrmeir1986" class="csl-entry" role="listitem">
Fahrmeir, &amp; Kaufmann, L. 1986. <span>“Asymptotic Inference in Discrete Response Models.”</span> <em>Statistische Hefte</em> 27 (1): 179–205. <a href="https://doi.org/10.1007/bf02932567">https://doi.org/10.1007/bf02932567</a>.
</div>
<div id="ref-gourieroux1981" class="csl-entry" role="listitem">
Gourieroux, &amp; Monfort, C. 1981. <span>“Asymptotic Properties of the Maximum Likelihood Estimator in Dichotomous Logit Models.”</span> <em>Journal of Econometrics</em> 17 (1): 83–97. <a href="https://doi.org/10.1016/0304-4076(81)90060-9">https://doi.org/10.1016/0304-4076(81)90060-9</a>.
</div>
<div id="ref-hastie2009" class="csl-entry" role="listitem">
Hastie, T., R. Tibshirani, and J. Friedman. 2009. <em>The Elements of Statistical Learning</em>. Springer New York. <a href="https://doi.org/10.1007/978-0-387-84858-7">https://doi.org/10.1007/978-0-387-84858-7</a>.
</div>
<div id="ref-hosmer2013" class="csl-entry" role="listitem">
Hosmer, David W., Stanley Lemeshow, and Rodney X. Sturdivant. 2013. <em>Applied Logistic Regression</em>. <em>Wiley Series in Probability and Statistics</em>. <a href="https://doi.org/10.1002/9781118548387">https://doi.org/10.1002/9781118548387</a>.
</div>
<div id="ref-islr2021" class="csl-entry" role="listitem">
James, G., D. Witten, T. Hastie, and R. Tibshirani. 2021. <em>An Introduction to Statistical Learning: With Applications in r</em>. Springer Texts in Statistics. Springer US. <a href="https://doi.org/10.1007/978-1-0716-1418">https://doi.org/10.1007/978-1-0716-1418</a>.
</div>
<div id="ref-nelder1972" class="csl-entry" role="listitem">
Nelder, J. A., and R. W. M. Wedderburn. 1972. <span>“Generalized Linear Models.”</span> <em>Journal of the Royal Statistical Society. Series A (General)</em> 135 (3): 370. <a href="https://doi.org/10.2307/2344614">https://doi.org/10.2307/2344614</a>.
</div>
</div>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>